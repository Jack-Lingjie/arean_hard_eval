执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500
文件 data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500.jsonl 存在, 跳过gen_answer.py 执行。
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
500 number of existing judgments
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.6, 0.8)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.4, 0.5)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.3, 1.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.3, 0.9)  | average #tokens: 767
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.1, 0.8)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.4, 1.0)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.4, 1.2)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.8, 0.4)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.5, 0.4)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.5, 0.3)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.3, 1.6)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.6, 1.4)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.0, 1.6)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.7, 1.5)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.7, 1.3)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.5, 1.7)  | average #tokens: 559
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-2.0, 1.4)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.0, 2.0)  | average #tokens: 767
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-1.0, 0.7)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 0.8)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 Done
运行时间: -28776200.73 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500
WARNING 09-17 04:53:04 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 04:53:04 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 04:53:04 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 04:53:05 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500...
INFO 09-17 04:54:09 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 04:54:09 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 04:54:12 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 04:54:12 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 04:54:22 model_runner.py:1181] Graph capturing finished in 9 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.5, 1.0)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.5, 1.1)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.8, 1.4)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.6, 1.7)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.5, 1.6)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.3, 1.2)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.5, 1.1)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.5, 2.0)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.6, 1.2)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.5, 0.4)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.2, 0.4)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.4, 1.1)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.6, 1.3)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.0, 2.3)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.4, 1.7)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.5, 1.5)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.4, 1.5)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.5, 1.7)  | average #tokens: 541
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.7, 1.4)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.1, 2.0)  | average #tokens: 767
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.6, 0.9)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 1.0)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 Done
运行时间: -28776233.00 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500
WARNING 09-17 05:37:41 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 05:37:41 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 05:37:41 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 05:37:42 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500...
INFO 09-17 05:38:48 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 05:38:49 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 05:38:52 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 05:38:52 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 05:39:01 model_runner.py:1181] Graph capturing finished in 9 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.3, 0.8)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.2, 1.4)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.2, 1.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.1, 1.2)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.3, 1.2)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.5, 0.8)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.1, 0.7)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.1, 1.3)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.0, 1.3)  | average #tokens: 546
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-0.9, 0.9)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.4)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.2, 1.1)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.4, 0.9)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.0, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.2, 1.8)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.3, 1.7)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.4, 1.4)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.3, 1.6)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.4, 1.3)  | average #tokens: 546
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.4, 1.5)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-1.9, 2.0)  | average #tokens: 767
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.6, 1.0)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.7, 0.7)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 Done
运行时间: -28776277.63 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500
WARNING 09-17 06:22:43 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 06:22:43 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 06:22:43 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 06:22:44 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500...
INFO 09-17 06:23:49 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 06:23:49 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 06:23:52 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 06:23:52 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 06:24:01 model_runner.py:1181] Graph capturing finished in 9 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.5, 1.2)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-2.2, 2.0)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.4, 2.1)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.1, 1.2)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.4, 1.1)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.6, 1.4)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.4, 1.2)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.2, 1.2)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.5, 1.5)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.1, 1.1)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.3)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Request timed out.
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.5, 1.3)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.7, 1.6)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.4, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-2.1, 1.5)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.9, 2.0)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.8, 1.5)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-2.2, 1.7)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-2.2, 1.7)  | average #tokens: 546
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.9, 2.0)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.5, 1.1)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.6, 2.4)  | average #tokens: 767
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.0)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.3, 1.1)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 Done
运行时间: -28776322.65 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500
WARNING 09-17 07:10:28 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 07:10:28 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 07:10:28 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 07:10:30 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500...
INFO 09-17 07:11:31 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 07:11:32 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 07:11:35 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 07:11:35 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 07:11:44 model_runner.py:1181] Graph capturing finished in 9 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.5, 1.0)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.7, 1.5)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.4, 2.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.4, 0.8)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.1, 1.3)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.2, 1.0)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.1, 1.5)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.2, 1.3)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.0, 1.0)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-0.9, 1.0)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.5, 1.1)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.4, 0.4)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 500 - {'code': 'FailedDependency', 'message': 'no healthy upstream', 'param': None, 'type': None}
Error code: 500 - {'code': 'FailedDependency', 'message': 'no healthy upstream', 'param': None, 'type': None}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.0, 1.2)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.2, 1.6)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.2, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.9, 1.4)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.8, 1.7)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.3, 2.0)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.6, 1.2)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.7, 1.4)  | average #tokens: 546
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.6, 1.4)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.3, 1.6)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-1.4, 1.4)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.0, 1.1)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.5, 1.0)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.0, 0.9)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 Done
运行时间: -28776370.41 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4
WARNING 09-17 07:55:59 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 07:55:59 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 07:55:59 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 07:56:00 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4...
INFO 09-17 07:57:11 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 07:57:11 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 07:57:14 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 07:57:14 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 07:57:23 model_runner.py:1181] Graph capturing finished in 9 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.2, 1.0)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.7, 1.6)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.5, 2.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.4, 0.9)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.5, 1.5)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.1, 0.9)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.0, 1.5)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.1, 1.5)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.9, 1.1)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.0, 0.8)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-0.9, 1.0)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-0.9, 0.9)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.4)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.4, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.1, 1.2)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.1, 1.6)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.3, 2.5)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.9, 1.5)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.6, 1.5)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.5, 2.1)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.7, 1.2)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.8, 1.2)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.8, 1.5)  | average #tokens: 546
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.8, 1.4)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.5, 1.8)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-1.6, 1.5)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.0, 1.2)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.6, 0.9)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.1, 0.8)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 Done
运行时间: -28776415.93 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5
WARNING 09-17 08:42:24 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 08:42:24 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 08:42:24 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 08:42:26 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5...
INFO 09-17 08:44:07 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 08:44:08 gpu_executor.py:102] # GPU blocks: 11983, # CPU blocks: 2048
INFO 09-17 08:44:12 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 08:44:12 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 08:44:24 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.5, 1.2)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.7, 1.7)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.8, 1.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.4, 0.9)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.4, 1.5)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.1, 1.1)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.1, 1.6)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.3, 1.5)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.6, 1.7)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.0, 1.6)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.1, 0.9)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-0.9, 0.9)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.3, 1.0)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.4, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Request timed out.
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.3, 1.4)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.5, 1.6)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.4, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-2.2, 1.8)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.5, 1.5)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.7, 2.0)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.8, 1.7)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.7, 1.2)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.9, 1.8)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.9, 1.8)  | average #tokens: 540
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.9, 1.5)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.4, 1.8)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-1.5, 1.6)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.0, 1.1)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.0)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.1, 0.8)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 Done
运行时间: -28776462.33 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6
WARNING 09-17 09:30:20 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 09:30:20 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 09:30:20 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 09:30:22 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6...
INFO 09-17 09:31:03 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 09:31:03 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 09:31:08 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 09:31:08 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 09:31:20 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.9, 1.1)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.3, 1.5)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-2.3, 1.6)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.8, 1.2)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.7, 1.4)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.1, 1.7)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.5, 1.3)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.4, 1.2)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.3, 1.7)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.3, 1.1)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.5, 1.9)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.1, 1.4)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.3, 1.8)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.6)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.5, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.3, 0.3)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.1, 1.5)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.7, 1.5)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.2, 2.6)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-2.1, 1.5)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.7, 1.8)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.5, 1.9)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.2, 1.4)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.4, 1.4)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.5, 2.5)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.8, 2.2)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.1, 2.2)  | average #tokens: 540
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-2.1, 1.5)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.4, 1.6)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.0, 1.6)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.1, 1.2)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 1.0)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 Done
运行时间: -28776510.30 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7
WARNING 09-17 10:15:46 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 10:15:46 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 10:15:46 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 10:15:48 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7...
INFO 09-17 10:16:28 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 10:16:28 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 10:16:32 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 10:16:32 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 10:16:43 model_runner.py:1181] Graph capturing finished in 11 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.8, 1.2)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.0, 1.5)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-2.1, 1.9)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.8, 1.3)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.7, 1.4)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.6, 1.5)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.0, 2.0)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.5, 1.4)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.5, 1.8)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.4, 1.7)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.3, 1.2)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.6, 2.1)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.7, 1.8)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.1, 1.3)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.4, 1.5)  | average #tokens: 528
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.6)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.5, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.3, 0.3)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Request timed out.
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.2, 1.5)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.7, 1.6)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.2, 2.7)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-2.1, 1.5)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.6, 1.1)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.6, 2.0)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.6, 1.5)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.6, 1.5)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.4, 2.2)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.9, 2.0)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.1, 2.1)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.5, 1.7)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-2.5, 2.5)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.6, 1.5)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-1.8, 1.5)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.2, 1.2)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 1.0)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 Done
运行时间: -28776555.71 分钟
----------------------------------------
执行参数: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8
WARNING 09-17 11:07:22 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 11:07:22 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 11:07:22 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 11:07:24 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8...
INFO 09-17 11:08:03 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 11:08:03 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 11:08:07 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 11:08:07 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 11:08:19 model_runner.py:1181] Graph capturing finished in 11 secs.
model name: tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8
use original template
Data saved to ./data/arena-ta/model_answer/tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8.jsonl
Text judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Error code: 503
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.6, 1.4)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.9, 1.6)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.6, 2.5)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.8, 1.3)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.5, 1.7)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.8, 1.8)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-0.9, 2.0)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.3, 1.5)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.5, 1.2)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.3, 1.6)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.2, 1.4)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.6, 2.2)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.8, 1.8)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.1, 1.4)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.1, 1.3)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.5, 0.5)  | average #tokens: 409
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.7, 0.6)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.5, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.3, 0.4)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.3, 1.5)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.9, 1.5)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.4, 2.6)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-2.2, 1.6)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.1, 1.8)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.7, 1.8)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-2.4, 1.8)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.5, 1.3)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.4, 2.2)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.8, 2.0)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.2, 2.2)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.6, 1.5)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.2, 1.9)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.5, 1.5)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.0, 1.5)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-1.4, 1.0)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.1, 1.1)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.8, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 1.0)  | average #tokens: 472
IMAGE judge tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 Done
运行时间: -28776607.33 分钟
----------------------------------------
执行参数: ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1
WARNING 09-17 11:54:20 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 11:54:20 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 11:54:20 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 11:54:21 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1...
INFO 09-17 11:55:01 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 11:55:02 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 11:55:06 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 11:55:06 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 11:55:17 model_runner.py:1181] Graph capturing finished in 11 secs.
model name: ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1
use original template
Data saved to ./data/arena-ta/model_answer/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1.jsonl
Text judge ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Error code: 503
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 52.5  | 95% CI: (-1.4, 2.0)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-1.9, 1.6)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.7, 2.7)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.8, 1.3)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.5, 1.7)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.8, 1.7)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.0, 2.0)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.4, 1.4)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.5, 1.3)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.3, 1.6)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.2, 1.3)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.7, 2.2)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.9, 1.8)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.1, 1.4)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.1, 1.3)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.5, 0.5)  | average #tokens: 409
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.7, 0.6)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.5, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.3, 0.4)  | average #tokens: 472
IMAGE judge ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 73.5  | 95% CI: (-1.6, 1.9)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.2, 1.5)  | average #tokens: 706
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.9, 1.5)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.5, 2.5)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-2.3, 1.6)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.2, 1.8)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.7, 1.9)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-2.4, 1.9)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.7, 1.4)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.7, 2.4)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.9, 2.1)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.1, 2.2)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.7, 1.4)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.3, 1.9)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.6, 1.5)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.0, 1.4)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-1.4, 1.0)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-1.1, 1.1)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 1.0)  | average #tokens: 472
IMAGE judge ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 Done
运行时间: -28776654.26 分钟
----------------------------------------
执行参数: ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500
WARNING 09-17 12:40:21 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 12:40:21 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 12:40:21 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 12:40:22 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500...
INFO 09-17 12:41:03 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 12:41:03 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 12:41:08 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 12:41:08 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 12:41:20 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500
use original template
Data saved to ./data/arena-ta/model_answer/ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500.jsonl
Text judge ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 52.5  | 95% CI: (-2.1, 1.9)  | average #tokens: 685
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 50.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 676
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.6, 1.8)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.0, 1.7)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.7, 1.9)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.4, 1.5)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.1, 1.1)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.5, 1.3)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.8, 2.0)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.6, 1.2)  | average #tokens: 672
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.9, 1.8)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.9, 1.5)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.0, 1.2)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.6, 1.3)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.8, 1.0)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.2, 0.7)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.3, 1.5)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.5, 0.7)  | average #tokens: 409
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.7, 0.5)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.5, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.3, 0.5)  | average #tokens: 472
IMAGE judge ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 73.5  | 95% CI: (-1.6, 1.7)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.6, 1.8)  | average #tokens: 706
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 70.8  | 95% CI: (-1.9, 1.8)  | average #tokens: 676
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.2, 2.2)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.6, 2.6)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.4, 1.5)  | average #tokens: 672
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.5, 1.6)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.5, 1.8)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.5, 1.8)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.5, 1.4)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.7, 1.3)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-2.0, 1.5)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.1, 1.6)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.4, 1.8)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.9, 2.1)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.3, 2.1)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.4, 2.2)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-1.1, 0.9)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-0.8, 1.1)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.1)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-0.9, 0.7)  | average #tokens: 472
IMAGE judge ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 Done
运行时间: -28776700.30 分钟
----------------------------------------
执行参数: ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500
WARNING 09-17 13:26:10 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 13:26:10 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 13:26:10 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 13:26:11 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500...
INFO 09-17 13:26:50 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 13:26:51 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 13:26:55 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 13:26:55 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 13:27:06 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500
use original template
Data saved to ./data/arena-ta/model_answer/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500.jsonl
Text judge ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 52.5  | 95% CI: (-1.6, 1.7)  | average #tokens: 685
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 50.8  | 95% CI: (-2.0, 1.8)  | average #tokens: 676
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.5, 2.0)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.0, 1.8)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-1.5, 1.5)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.4, 1.6)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.0, 1.2)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.5, 1.1)  | average #tokens: 677
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.8, 1.8)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.4, 1.3)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 24.3  | 95% CI: (-1.4, 1.7)  | average #tokens: 627
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-1.8, 1.4)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.9, 1.6)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.4, 1.2)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.8, 1.3)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.8, 0.9)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.3, 0.6)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-1.3, 1.1)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.5, 0.5)  | average #tokens: 409
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.4, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.3, 0.5)  | average #tokens: 472
IMAGE judge ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Request timed out.
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Invalid image data.', 'param': None, 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 73.5  | 95% CI: (-2.0, 1.9)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.5, 1.9)  | average #tokens: 706
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 70.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 676
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.3, 2.1)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.6, 2.6)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.3, 1.4)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 59.8  | 95% CI: (-1.4, 1.6)  | average #tokens: 627
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.6, 1.7)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.4, 1.9)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.5, 2.0)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.6, 1.3)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.9, 1.4)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-2.2, 1.4)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.1, 1.5)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.7, 1.9)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.7, 2.2)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.6, 1.9)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.7, 2.3)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-0.8, 0.9)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-0.8, 1.3)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.8, 1.0)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.0, 0.6)  | average #tokens: 472
IMAGE judge ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 Done
运行时间: -28776746.10 分钟
----------------------------------------
执行参数: ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000
WARNING 09-17 14:15:16 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 14:15:16 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 14:15:16 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 14:15:17 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000...
INFO 09-17 14:15:55 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 14:15:55 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 14:16:00 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 14:16:00 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 14:16:11 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000
use original template
Data saved to ./data/arena-ta/model_answer/ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000.jsonl
Text judge ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 52.5  | 95% CI: (-1.9, 1.6)  | average #tokens: 685
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 50.8  | 95% CI: (-2.2, 1.6)  | average #tokens: 676
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.4, 2.1)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.4, 1.4)  | average #tokens: 663
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-2.4, 1.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.9, 1.5)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.4, 1.2)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.5, 1.4)  | average #tokens: 677
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 | score: 26.5  | 95% CI: (-1.4, 1.4)  | average #tokens: 689
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.5, 1.1)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.3, 1.2)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 24.3  | 95% CI: (-2.1, 1.1)  | average #tokens: 627
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-2.2, 1.7)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.7, 1.4)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.6, 1.3)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-1.9, 2.0)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.4, 1.4)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.5, 0.9)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-2.1, 1.6)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.6, 0.6)  | average #tokens: 409
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.5, 0.6)  | average #tokens: 420
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 73.5  | 95% CI: (-1.6, 1.9)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.5, 2.0)  | average #tokens: 706
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 70.8  | 95% CI: (-1.8, 1.7)  | average #tokens: 676
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.3, 2.2)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 | score: 62.1  | 95% CI: (-1.8, 1.5)  | average #tokens: 689
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.3, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.5, 1.2)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 59.8  | 95% CI: (-1.8, 1.8)  | average #tokens: 627
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.8, 2.1)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.4, 1.8)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.6, 1.6)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.4, 1.4)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-1.9, 1.2)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.7, 1.4)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.2, 1.9)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.3, 1.6)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.4, 1.8)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.5, 1.7)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.3, 2.3)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-1.2, 1.0)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-0.8, 1.3)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.7, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.0, 0.7)  | average #tokens: 472
IMAGE judge ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 Done
运行时间: -28776795.21 分钟
----------------------------------------
执行参数: ta_rejected_llama3.1_instruct_2048_default_template_v2-500
WARNING 09-17 15:02:48 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 15:02:48 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 15:02:48 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 15:02:50 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-500...
INFO 09-17 15:03:29 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 15:03:29 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 15:03:33 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 15:03:33 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 15:03:45 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: ta_rejected_llama3.1_instruct_2048_default_template_v2-500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-500
use original template
Data saved to ./data/arena-ta/model_answer/ta_rejected_llama3.1_instruct_2048_default_template_v2-500.jsonl
Text judge ta_rejected_llama3.1_instruct_2048_default_template_v2-500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_llama3.1_instruct_2048_default_template_v2-500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 52.5  | 95% CI: (-1.9, 1.9)  | average #tokens: 685
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 50.8  | 95% CI: (-2.2, 1.6)  | average #tokens: 676
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.6, 2.1)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.6, 1.4)  | average #tokens: 663
ta_rejected_llama3.1_instruct_2048_default_template_v2-500 | score: 47.9  | 95% CI: (-2.6, 1.9)  | average #tokens: 659
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-2.3, 1.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.9, 1.6)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.4, 1.2)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.4, 1.4)  | average #tokens: 677
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 | score: 26.5  | 95% CI: (-1.5, 1.4)  | average #tokens: 689
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.5, 1.1)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.3, 1.2)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 24.3  | 95% CI: (-2.0, 1.1)  | average #tokens: 627
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-2.2, 1.5)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.6, 1.4)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.6, 1.2)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-2.1, 1.9)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.4, 1.4)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.7, 0.9)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-2.3, 1.6)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.6, 0.6)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.5, 0.6)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge ta_rejected_llama3.1_instruct_2048_default_template_v2-500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-500', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate ta_rejected_llama3.1_instruct_2048_default_template_v2-500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_llama3.1_instruct_2048_default_template_v2-500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images ta_rejected_llama3.1_instruct_2048_default_template_v2-500
Request timed out.
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 73.5  | 95% CI: (-2.0, 2.3)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.8, 1.8)  | average #tokens: 706
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 70.8  | 95% CI: (-2.4, 1.8)  | average #tokens: 676
ta_rejected_llama3.1_instruct_2048_default_template_v2-500 | score: 69.4  | 95% CI: (-1.7, 2.0)  | average #tokens: 659
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.3, 2.1)  | average #tokens: 663
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 | score: 62.1  | 95% CI: (-2.0, 1.5)  | average #tokens: 689
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.7, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.5, 1.3)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 59.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 627
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.9, 2.4)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.7, 1.8)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-2.0, 1.7)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.4, 1.4)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-2.2, 1.4)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.8, 1.4)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.5, 2.0)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.5, 1.6)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.7, 2.0)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.7, 1.6)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.4, 2.2)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-1.2, 1.0)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-0.8, 1.2)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.8, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.0, 0.8)  | average #tokens: 472
IMAGE judge ta_rejected_llama3.1_instruct_2048_default_template_v2-500 Done
运行时间: -28776842.75 分钟
----------------------------------------
执行参数: ta_rejected_llama3.1_instruct_2048_default_template_v2-1000
WARNING 09-17 15:52:02 arg_utils.py:762] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-17 15:52:02 config.py:806] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-17 15:52:02 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-1000, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-17 15:52:03 model_runner.py:680] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-1000...
INFO 09-17 15:52:43 model_runner.py:692] Loading model weights took 14.9888 GB
INFO 09-17 15:52:43 gpu_executor.py:102] # GPU blocks: 12310, # CPU blocks: 2048
INFO 09-17 15:52:47 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-17 15:52:47 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-17 15:52:59 model_runner.py:1181] Graph capturing finished in 12 secs.
model name: ta_rejected_llama3.1_instruct_2048_default_template_v2-1000
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/ta_rejected_llama3.1_instruct_2048_default_template_v2-1000
use original template
Data saved to ./data/arena-ta/model_answer/ta_rejected_llama3.1_instruct_2048_default_template_v2-1000.jsonl
Text judge ta_rejected_llama3.1_instruct_2048_default_template_v2-1000 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Error code: 503
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Error code: 503
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Error code: 503
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Error code: 503
upstream connect error or disconnect/reset before headers. retried and the latest reset reason: protocol error
Error code: 503
Namespace(bench_name='arena-ta', judge_name='gpt-4o_text', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='text', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 52.5  | 95% CI: (-2.0, 2.0)  | average #tokens: 685
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 50.8  | 95% CI: (-2.1, 1.5)  | average #tokens: 676
ta_chosen_llama3.1_instruct_dpo_2048 | score: 50.1  | 95% CI: (-1.7, 2.0)  | average #tokens: 706
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
ta_rejected_llama3.1_instruct_2048_default_template_v2-1000 | score: 49.6  | 95% CI: (-1.9, 2.6)  | average #tokens: 649
ta_rejected_llama3.1_instruct_dpo_2048 | score: 48.1  | 95% CI: (-2.5, 1.6)  | average #tokens: 663
ta_rejected_llama3.1_instruct_2048_default_template_v2-500 | score: 47.9  | 95% CI: (-2.0, 1.4)  | average #tokens: 659
uf_llama3.1_instruct_dpo_2048_job | score: 32.5  | 95% CI: (-2.4, 1.2)  | average #tokens: 687
Meta-Llama-3.1-8B-Instruct     | score: 32.1  | 95% CI: (-1.8, 1.7)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 28.1  | 95% CI: (-1.4, 1.3)  | average #tokens: 541
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 26.5  | 95% CI: (-1.4, 1.5)  | average #tokens: 677
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 | score: 26.5  | 95% CI: (-1.5, 1.5)  | average #tokens: 689
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 25.4  | 95% CI: (-1.5, 1.3)  | average #tokens: 559
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 25.1  | 95% CI: (-1.3, 1.2)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 24.3  | 95% CI: (-1.9, 1.1)  | average #tokens: 627
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 24.2  | 95% CI: (-2.2, 1.7)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 24.2  | 95% CI: (-1.8, 1.5)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 23.3  | 95% CI: (-1.5, 1.3)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 22.7  | 95% CI: (-2.0, 2.0)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 22.0  | 95% CI: (-1.4, 1.6)  | average #tokens: 552
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 21.5  | 95% CI: (-1.7, 0.9)  | average #tokens: 550
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 19.3  | 95% CI: (-2.3, 1.6)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score:  2.8  | 95% CI: (-0.6, 0.6)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score:  2.4  | 95% CI: (-0.6, 0.5)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  2.4  | 95% CI: (-0.5, 0.6)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  1.2  | 95% CI: (-0.4, 0.4)  | average #tokens: 472
IMAGE judge ta_rejected_llama3.1_instruct_2048_default_template_v2-1000 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-500', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'uf_llama3.1_instruct_dpo_2048_job'])
-----------------generate ta_rejected_llama3.1_instruct_2048_default_template_v2-1000 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images ta_rejected_llama3.1_instruct_2048_default_template_v2-1000
Error code: 500 - {'error': {'code': 'InternalServerError', 'message': 'The service is temporarily unable to process your request. Please try again later.', 'param': None, 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 503 - {'error': {'code': 'ServiceUnavailable', 'message': 'Service unavailable', 'param': None, 'type': None}}
Error code: 500 - {'error': {'code': 'InternalServerError', 'message': 'The service is temporarily unable to process your request. Please try again later.', 'param': None, 'type': None}}
Error code: 500 - {'error': {'code': 'InternalServerError', 'message': 'The service is temporarily unable to process your request. Please try again later.', 'param': None, 'type': None}}
Error code: 424 - {'error': {'message': 'Error occurred while processing image(s).', 'type': 'failed_dependency', 'param': None, 'code': None}}
Error code: 503 - {'error': {'code': 'ServiceUnavailable', 'message': 'Service unavailable', 'param': None, 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Namespace(bench_name='arena-ta', judge_name='gpt-4o_images', baseline='gpt4_1106_preview', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output='image', first_game_only=False)
Turning judgment results into battles...
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1 | score: 73.5  | 95% CI: (-1.9, 1.7)  | average #tokens: 685
ta_chosen_llama3.1_instruct_dpo_2048 | score: 73.3  | 95% CI: (-1.7, 1.9)  | average #tokens: 706
ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500 | score: 70.8  | 95% CI: (-2.0, 1.7)  | average #tokens: 676
ta_rejected_llama3.1_instruct_2048_default_template_v2-500 | score: 69.4  | 95% CI: (-2.0, 1.7)  | average #tokens: 659
ta_rejected_llama3.1_instruct_dpo_2048 | score: 69.3  | 95% CI: (-1.4, 2.2)  | average #tokens: 663
ta_rejected_llama3.1_instruct_2048_default_template_v2-1000 | score: 69.3  | 95% CI: (-2.4, 1.3)  | average #tokens: 649
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000 | score: 62.1  | 95% CI: (-1.8, 1.6)  | average #tokens: 689
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.7  | 95% CI: (-1.7, 2.4)  | average #tokens: 677
ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 60.4  | 95% CI: (-1.6, 1.3)  | average #tokens: 672
ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500 | score: 59.8  | 95% CI: (-1.9, 1.8)  | average #tokens: 627
ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2 | score: 57.7  | 95% CI: (-1.9, 2.2)  | average #tokens: 528
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500 | score: 56.1  | 95% CI: (-1.5, 1.9)  | average #tokens: 559
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4 | score: 55.5  | 95% CI: (-1.8, 1.7)  | average #tokens: 529
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500 | score: 53.4  | 95% CI: (-1.6, 1.5)  | average #tokens: 541
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6 | score: 52.7  | 95% CI: (-2.1, 1.4)  | average #tokens: 543
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500 | score: 52.5  | 95% CI: (-1.9, 1.4)  | average #tokens: 546
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5 | score: 51.7  | 95% CI: (-1.4, 1.8)  | average #tokens: 540
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7 | score: 50.1  | 95% CI: (-1.4, 1.5)  | average #tokens: 552
gpt4_1106_preview              | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 0
uf_llama3.1_instruct_dpo_2048_job | score: 49.6  | 95% CI: (-1.5, 1.9)  | average #tokens: 687
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500 | score: 48.3  | 95% CI: (-1.7, 1.9)  | average #tokens: 550
Meta-Llama-3.1-8B-Instruct     | score: 46.3  | 95% CI: (-2.3, 2.2)  | average #tokens: 767
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8 | score: 11.7  | 95% CI: (-1.3, 1.1)  | average #tokens: 409
tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500 | score: 10.9  | 95% CI: (-0.8, 1.2)  | average #tokens: 419
tulu_v2_8b_2048_default_template_dpo | score:  9.6  | 95% CI: (-0.8, 1.2)  | average #tokens: 420
tulu_v2_8b_2048_default_template_sft | score:  9.4  | 95% CI: (-1.0, 0.8)  | average #tokens: 472
IMAGE judge ta_rejected_llama3.1_instruct_2048_default_template_v2-1000 Done
运行时间: -28776891.98 分钟
----------------------------------------
所有任务已完成。
