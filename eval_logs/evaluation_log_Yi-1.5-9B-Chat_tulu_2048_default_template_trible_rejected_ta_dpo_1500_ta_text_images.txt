执行参数: Yi-1.5-9B-Chat
文件 data/arena-ta/model_answer/Yi-1.5-9B-Chat.jsonl 存在, 跳过gen_answer.py 执行。
Text judge Yi-1.5-9B-Chat Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='Yi-1.5-9B-Chat', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
500 number of existing judgments
IMAGE judge Yi-1.5-9B-Chat Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'Meta-Llama-3.1-8B', 'Qwen2-7B-Instruct', 'WizardLM-13B-V1.2', 'Yi-1.5-9B-Chat', 'Yi-34B-Chat', 'gemma-2-27b-it', 'gemma-2-9b-it', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_chosen_llama3.1_instruct_dpo_2048_v2', 'ta_chosen_llama3.1_instruct_dpo_2048_v2_1000', 'ta_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v10', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v11', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v15', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v15_1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v2-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v4', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v5', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v5_1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v6', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v9', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-500', 'ta_rejected_llama3.1_instruct_2048_default_template_v2', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu-2-dpo-13b', 'tulu_2048_default_template_trible_chosen_ta_dpo', 'tulu_2048_default_template_trible_rejected_ta_dpo', 'tulu_uf_ta_v2_2048_default_template_dpo_1500', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v10', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v10_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v11', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v11_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v14', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v15', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v15_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v2', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v3', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v9-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v9', 'uf_llama3.1_instruct_dpo_2048_job', 'uf_llama3.1_instruct_dpo_2048_trible', 'uf_llama3.1_instruct_dpo_2048_trible_ta_chosen', 'uf_llama3.1_instruct_dpo_2048_trible_ta_rejected', 'vicuna-13b-v1.5', 'vicuna-33b-v1.3'])
-----------------generate Yi-1.5-9B-Chat images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='Yi-1.5-9B-Chat', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images Yi-1.5-9B-Chat
500 number of existing judgments
IMAGE judge Yi-1.5-9B-Chat Done
运行时间: -28787340.21 分钟
----------------------------------------
执行参数: tulu_2048_default_template_trible_rejected_ta_dpo_1500
WARNING 09-25 05:01:09 arg_utils.py:766] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 09-25 05:01:09 config.py:820] Chunked prefill is enabled with max_num_batched_tokens=512.
INFO 09-25 05:01:09 llm_engine.py:174] Initializing an LLM engine (v0.5.4) with config: model='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_2048_default_template_trible_rejected_ta_dpo_1500', speculative_config=None, tokenizer='/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_2048_default_template_trible_rejected_ta_dpo_1500', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_2048_default_template_trible_rejected_ta_dpo_1500, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 09-25 05:01:17 model_runner.py:720] Starting to load model /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_2048_default_template_trible_rejected_ta_dpo_1500...
INFO 09-25 05:01:43 model_runner.py:732] Loading model weights took 14.9888 GB
INFO 09-25 05:01:43 gpu_executor.py:102] # GPU blocks: 28232, # CPU blocks: 2048
INFO 09-25 05:01:46 model_runner.py:1024] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 09-25 05:01:46 model_runner.py:1028] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 09-25 05:01:55 model_runner.py:1225] Graph capturing finished in 9 secs.
model name: tulu_2048_default_template_trible_rejected_ta_dpo_1500
model_path: /mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/tulu_2048_default_template_trible_rejected_ta_dpo_1500
use original template
Data saved to ./data/arena-ta/model_answer/tulu_2048_default_template_trible_rejected_ta_dpo_1500.jsonl
Text judge tulu_2048_default_template_trible_rejected_ta_dpo_1500 Begin
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_2048_default_template_trible_rejected_ta_dpo_1500', baseline_model='gpt-4-1106-preview', bench_name='arena-ta')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
IMAGE judge tulu_2048_default_template_trible_rejected_ta_dpo_1500 Begin
model_answers.keys() dict_keys(['Meta-Llama-3.1-8B-Instruct', 'Meta-Llama-3.1-8B', 'Qwen2-7B-Instruct', 'WizardLM-13B-V1.2', 'Yi-1.5-9B-Chat', 'Yi-34B-Chat', 'gemma-2-27b-it', 'gemma-2-9b-it', 'gpt-4-1106-preview', 'ta_chosen_llama3.1_instruct_dpo_2048', 'ta_chosen_llama3.1_instruct_dpo_2048_v2', 'ta_chosen_llama3.1_instruct_dpo_2048_v2_1000', 'ta_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v1', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v10', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v11', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v15', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v15_1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v2-1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v4', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v5', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v5_1500', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v6', 'ta_llama3_instruct_dpo_list_bsz1_trible_debug_v9', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-1000', 'ta_rejected_llama3.1_instruct_2048_default_template_v2-500', 'ta_rejected_llama3.1_instruct_2048_default_template_v2', 'ta_rejected_llama3.1_instruct_dpo_2048', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_1000', 'ta_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2_500', 'ta_v2_chosen_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'ta_v2_rejected_tuluv2_dpo_2048_default_template_bsz1_acc8_v2', 'tulu-2-dpo-13b', 'tulu_2048_default_template_trible_chosen_ta_dpo', 'tulu_2048_default_template_trible_rejected_ta_dpo', 'tulu_2048_default_template_trible_rejected_ta_dpo_1500', 'tulu_uf_ta_v2_2048_default_template_dpo_1500', 'tulu_v2_8b_2048_default_template_dpo', 'tulu_v2_8b_2048_default_template_sft', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v10', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v10_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v11', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v11_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v14', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v15', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v15_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v2', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v3', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v4', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v5_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v6_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v7_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v8_1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v9-1500', 'tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug_v9', 'uf_llama3.1_instruct_dpo_2048_job', 'uf_llama3.1_instruct_dpo_2048_trible', 'uf_llama3.1_instruct_dpo_2048_trible_ta_chosen', 'uf_llama3.1_instruct_dpo_2048_trible_ta_rejected', 'vicuna-13b-v1.5', 'vicuna-33b-v1.3'])
-----------------generate tulu_2048_default_template_trible_rejected_ta_dpo_1500 images -----------------
images generated done.
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml', model_name='tulu_2048_default_template_trible_rejected_ta_dpo_1500', baseline_model='gpt-4-1106-preview')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-1106-preview, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
generate images tulu_2048_default_template_trible_rejected_ta_dpo_1500
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \r\nhttps://go.microsoft.com/fwlink/?linkid=2198766.", 'param': 'prompt', 'type': None}}
IMAGE judge tulu_2048_default_template_trible_rejected_ta_dpo_1500 Done
运行时间: -28787341.06 分钟
----------------------------------------
所有任务已完成。
