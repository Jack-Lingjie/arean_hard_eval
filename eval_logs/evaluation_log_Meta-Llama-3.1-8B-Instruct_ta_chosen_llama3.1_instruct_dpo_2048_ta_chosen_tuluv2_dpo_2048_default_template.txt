执行参数: Meta-Llama-3.1-8B-Instruct
文件 data/arena-hard-v0.1/model_answer/Meta-Llama-3.1-8B-Instruct.jsonl 存在，跳过 vllm 服务启动和 gen_answer.py 执行。
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-0314, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-hard-v0.1', judge_name='gpt-4-1106-preview', baseline='gpt-4-0314', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output=True, first_game_only=False)
Turning judgment results into battles...
gpt-4-turbo-2024-04-09         | score: 82.6  | 95% CI: (-1.4, 1.7)  | average #tokens: 662
claude-3-5-sonnet-20240620     | score: 79.3  | 95% CI: (-2.0, 1.8)  | average #tokens: 567
gpt-4o-2024-05-13              | score: 79.2  | 95% CI: (-2.1, 2.0)  | average #tokens: 696
gpt-4-0125-preview             | score: 78.0  | 95% CI: (-2.3, 1.8)  | average #tokens: 619
athene-70b                     | score: 76.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 683
gpt-4o-mini                    | score: 74.9  | 95% CI: (-1.8, 3.0)  | average #tokens: 668
gemini-1.5-pro-api-0514        | score: 72.0  | 95% CI: (-2.2, 2.2)  | average #tokens: 676
yi-large-preview               | score: 71.5  | 95% CI: (-2.1, 1.8)  | average #tokens: 720
mistral-large-2407             | score: 70.4  | 95% CI: (-2.1, 2.9)  | average #tokens: 623
llama-3.1-405b-instruct        | score: 64.1  | 95% CI: (-2.7, 2.0)  | average #tokens: 633
glm-4-0520                     | score: 63.8  | 95% CI: (-2.2, 2.5)  | average #tokens: 636
yi-large                       | score: 63.7  | 95% CI: (-2.7, 2.2)  | average #tokens: 626
deepseek-coder-v2              | score: 62.3  | 95% CI: (-2.3, 2.2)  | average #tokens: 578
claude-3-opus-20240229         | score: 60.4  | 95% CI: (-2.2, 2.2)  | average #tokens: 541
gemma-2-27b-it                 | score: 57.5  | 95% CI: (-2.9, 2.5)  | average #tokens: 577
llama-3.1-70b-instruct         | score: 55.7  | 95% CI: (-3.0, 2.6)  | average #tokens: 628
glm-4-0116                     | score: 55.7  | 95% CI: (-2.0, 2.1)  | average #tokens: 622
gemini-1.5-pro-api-0409-preview | score: 53.4  | 95% CI: (-2.2, 3.3)  | average #tokens: 478
glm-4-air                      | score: 50.9  | 95% CI: (-2.4, 2.7)  | average #tokens: 619
gpt-4-0314                     | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 423
gemini-1.5-flash-api-0514      | score: 49.6  | 95% CI: (-2.1, 2.6)  | average #tokens: 642
qwen2-72b-instruct             | score: 46.9  | 95% CI: (-2.3, 3.0)  | average #tokens: 515
claude-3-sonnet-20240229       | score: 46.8  | 95% CI: (-2.4, 1.6)  | average #tokens: 552
llama-3-70b-instruct           | score: 46.6  | 95% CI: (-2.5, 3.5)  | average #tokens: 591
wildchat_v2_8b_2048_default_template_fullft_lr5e6_e5_9485 | score: 42.9  | 95% CI: (-2.4, 2.1)  | average #tokens: 684
claude-3-haiku-20240307        | score: 41.5  | 95% CI: (-2.0, 2.4)  | average #tokens: 505
gpt-4-0613                     | score: 37.9  | 95% CI: (-2.9, 1.9)  | average #tokens: 354
mistral-large-2402             | score: 37.7  | 95% CI: (-2.5, 2.9)  | average #tokens: 400
Meta-Llama-3.1-8B-Instruct     | score: 37.5  | 95% CI: (-6.0, 5.9)  | average #tokens: 731
wildchat_v2_8b_2048_default_template_fullft_lr5e6_3794 | score: 36.9  | 95% CI: (-2.3, 2.3)  | average #tokens: 682
mixtral-8x22b-instruct-v0.1    | score: 36.4  | 95% CI: (-2.4, 2.5)  | average #tokens: 430
qwen1.5-72b-chat               | score: 36.1  | 95% CI: (-2.6, 2.0)  | average #tokens: 474
phi-3-medium-4k-instruct       | score: 33.4  | 95% CI: (-2.0, 2.4)  | average #tokens: 517
command-r-plus                 | score: 33.1  | 95% CI: (-2.6, 2.1)  | average #tokens: 541
mistral-medium                 | score: 31.9  | 95% CI: (-2.2, 2.5)  | average #tokens: 485
wildchat_v1_8b_2048_default_template | score: 30.7  | 95% CI: (-2.8, 2.2)  | average #tokens: 756
phi-3-small-8k-instruct        | score: 29.8  | 95% CI: (-1.5, 2.2)  | average #tokens: 568
ta_chosen_llama3.1_instruct_dpo_2048 | score: 28.7  | 95% CI: (-2.1, 1.9)  | average #tokens: 662
wildchat_v2_8b_2048_default_template_3796 | score: 28.1  | 95% CI: (-2.2, 1.6)  | average #tokens: 787
ta_rejected_llama3.1_instruct_dpo_2048 | score: 28.0  | 95% CI: (-1.8, 2.3)  | average #tokens: 646
mistral-next                   | score: 27.4  | 95% CI: (-2.2, 2.3)  | average #tokens: 297
wildchat_v2_8b_2048_default_template_fullft_e5_9485 | score: 26.7  | 95% CI: (-1.9, 2.0)  | average #tokens: 699
wildchat_v2_8b_2048_default_template_full_sft | score: 26.5  | 95% CI: (-1.7, 2.1)  | average #tokens: 669
wildchat_v1_8b_2048_default_template_4000 | score: 25.5  | 95% CI: (-2.0, 2.0)  | average #tokens: 742
gpt-3.5-turbo-0613             | score: 24.8  | 95% CI: (-2.1, 2.0)  | average #tokens: 401
dbrx-instruct-preview          | score: 24.6  | 95% CI: (-1.7, 2.3)  | average #tokens: 415
claude-2.0                     | score: 24.0  | 95% CI: (-1.7, 2.0)  | average #tokens: 295
mixtral-8x7b-instruct-v0.1     | score: 23.4  | 95% CI: (-1.8, 2.2)  | average #tokens: 457
gpt-3.5-turbo-0125             | score: 23.3  | 95% CI: (-2.1, 2.3)  | average #tokens: 329
yi-34b-chat                    | score: 23.1  | 95% CI: (-1.8, 1.7)  | average #tokens: 611
starling-lm-7b-beta            | score: 23.0  | 95% CI: (-1.9, 2.0)  | average #tokens: 530
claude-2.1                     | score: 22.8  | 95% CI: (-1.6, 2.0)  | average #tokens: 290
llama-3.1-8b-instruct          | score: 21.3  | 95% CI: (-1.9, 1.4)  | average #tokens: 861
snorkel-mistral-pairrm-dpo     | score: 20.7  | 95% CI: (-1.9, 1.9)  | average #tokens: 564
llama-3-8b-instruct            | score: 20.6  | 95% CI: (-1.8, 1.9)  | average #tokens: 585
gpt-3.5-turbo-1106             | score: 18.9  | 95% CI: (-1.9, 1.9)  | average #tokens: 285
gpt-3.5-turbo-0314             | score: 18.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 334
gemini-pro                     | score: 17.8  | 95% CI: (-1.6, 1.6)  | average #tokens: 322
snowflake-arctic-instruct      | score: 17.6  | 95% CI: (-2.0, 1.9)  | average #tokens: 365
command-r                      | score: 17.0  | 95% CI: (-1.8, 1.7)  | average #tokens: 432
phi-3-mini-128k-instruct       | score: 15.4  | 95% CI: (-1.4, 1.5)  | average #tokens: 609
tulu-2-dpo-70b                 | score: 15.0  | 95% CI: (-1.8, 1.4)  | average #tokens: 550
starling-lm-7b-alpha           | score: 12.8  | 95% CI: (-1.6, 1.4)  | average #tokens: 483
mistral-7b-instruct            | score: 12.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 541
gemma-1.1-7b-it                | score: 12.1  | 95% CI: (-1.0, 1.3)  | average #tokens: 341
llama-2-70b-chat               | score: 11.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 595
vicuna-33b                     | score:  8.6  | 95% CI: (-1.4, 1.0)  | average #tokens: 451
gemma-7b-it                    | score:  7.5  | 95% CI: (-1.1, 1.1)  | average #tokens: 378
tulu_v2_8b_base_template_dpo   | score:  7.2  | 95% CI: (-0.9, 0.9)  | average #tokens: 496
tulu_v2_8b_bsz64_default_template_dpo | score:  7.0  | 95% CI: (-1.1, 1.3)  | average #tokens: 449
tulu_v2_8b_2048_default_template_dpo | score:  6.6  | 95% CI: (-0.9, 1.1)  | average #tokens: 463
tulu-2-dpo-7b                  | score:  6.0  | 95% CI: (-0.8, 0.9)  | average #tokens: 539
tulu_v2_8b_2048_default_template_sft | score:  5.1  | 95% CI: (-0.8, 1.0)  | average #tokens: 441
ta_chosen_tuluv2_dpo_2048_default_template | score:  4.7  | 95% CI: (-0.9, 0.9)  | average #tokens: 758
tulu_lora_sft_default_template_8b | score:  4.3  | 95% CI: (-0.8, 0.7)  | average #tokens: 444
tulu_lora_sft_base_template_8b | score:  4.3  | 95% CI: (-0.6, 0.8)  | average #tokens: 458
gemma-1.1-2b-it                | score:  3.4  | 95% CI: (-0.6, 0.7)  | average #tokens: 316
gemma-2b-it                    | score:  3.0  | 95% CI: (-0.7, 0.6)  | average #tokens: 369
tulu-2-7b                      | score:  2.5  | 95% CI: (-0.6, 0.6)  | average #tokens: 413
Meta-Llama-3.1-8B              | score:  0.5  | 95% CI: (-0.2, 0.3)  | average #tokens: 1616
所有任务已完成，vllm 服务已关闭。
运行时间: -28748935.81 分钟
----------------------------------------
执行参数: ta_chosen_llama3.1_instruct_dpo_2048
文件 data/arena-hard-v0.1/model_answer/ta_chosen_llama3.1_instruct_dpo_2048.jsonl 存在，跳过 vllm 服务启动和 gen_answer.py 执行。
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-0314, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-hard-v0.1', judge_name='gpt-4-1106-preview', baseline='gpt-4-0314', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output=True, first_game_only=False)
Turning judgment results into battles...
gpt-4-turbo-2024-04-09         | score: 82.6  | 95% CI: (-1.4, 1.7)  | average #tokens: 662
claude-3-5-sonnet-20240620     | score: 79.3  | 95% CI: (-2.0, 1.8)  | average #tokens: 567
gpt-4o-2024-05-13              | score: 79.2  | 95% CI: (-2.1, 2.0)  | average #tokens: 696
gpt-4-0125-preview             | score: 78.0  | 95% CI: (-2.3, 1.8)  | average #tokens: 619
athene-70b                     | score: 76.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 683
gpt-4o-mini                    | score: 74.9  | 95% CI: (-1.8, 3.0)  | average #tokens: 668
gemini-1.5-pro-api-0514        | score: 72.0  | 95% CI: (-2.2, 2.2)  | average #tokens: 676
yi-large-preview               | score: 71.5  | 95% CI: (-2.1, 1.8)  | average #tokens: 720
mistral-large-2407             | score: 70.4  | 95% CI: (-2.1, 2.9)  | average #tokens: 623
llama-3.1-405b-instruct        | score: 64.1  | 95% CI: (-2.7, 2.0)  | average #tokens: 633
glm-4-0520                     | score: 63.8  | 95% CI: (-2.2, 2.5)  | average #tokens: 636
yi-large                       | score: 63.7  | 95% CI: (-2.7, 2.2)  | average #tokens: 626
deepseek-coder-v2              | score: 62.3  | 95% CI: (-2.3, 2.2)  | average #tokens: 578
claude-3-opus-20240229         | score: 60.4  | 95% CI: (-2.2, 2.2)  | average #tokens: 541
gemma-2-27b-it                 | score: 57.5  | 95% CI: (-2.9, 2.5)  | average #tokens: 577
llama-3.1-70b-instruct         | score: 55.7  | 95% CI: (-3.0, 2.6)  | average #tokens: 628
glm-4-0116                     | score: 55.7  | 95% CI: (-2.0, 2.1)  | average #tokens: 622
gemini-1.5-pro-api-0409-preview | score: 53.4  | 95% CI: (-2.2, 3.3)  | average #tokens: 478
glm-4-air                      | score: 50.9  | 95% CI: (-2.4, 2.7)  | average #tokens: 619
gpt-4-0314                     | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 423
gemini-1.5-flash-api-0514      | score: 49.6  | 95% CI: (-2.1, 2.6)  | average #tokens: 642
qwen2-72b-instruct             | score: 46.9  | 95% CI: (-2.3, 3.0)  | average #tokens: 515
claude-3-sonnet-20240229       | score: 46.8  | 95% CI: (-2.4, 1.6)  | average #tokens: 552
llama-3-70b-instruct           | score: 46.6  | 95% CI: (-2.5, 3.5)  | average #tokens: 591
wildchat_v2_8b_2048_default_template_fullft_lr5e6_e5_9485 | score: 42.9  | 95% CI: (-2.4, 2.1)  | average #tokens: 684
claude-3-haiku-20240307        | score: 41.5  | 95% CI: (-2.0, 2.4)  | average #tokens: 505
gpt-4-0613                     | score: 37.9  | 95% CI: (-2.9, 1.9)  | average #tokens: 354
mistral-large-2402             | score: 37.7  | 95% CI: (-2.5, 2.9)  | average #tokens: 400
Meta-Llama-3.1-8B-Instruct     | score: 37.5  | 95% CI: (-6.0, 5.9)  | average #tokens: 731
wildchat_v2_8b_2048_default_template_fullft_lr5e6_3794 | score: 36.9  | 95% CI: (-2.3, 2.3)  | average #tokens: 682
mixtral-8x22b-instruct-v0.1    | score: 36.4  | 95% CI: (-2.4, 2.5)  | average #tokens: 430
qwen1.5-72b-chat               | score: 36.1  | 95% CI: (-2.6, 2.0)  | average #tokens: 474
phi-3-medium-4k-instruct       | score: 33.4  | 95% CI: (-2.0, 2.4)  | average #tokens: 517
command-r-plus                 | score: 33.1  | 95% CI: (-2.6, 2.1)  | average #tokens: 541
mistral-medium                 | score: 31.9  | 95% CI: (-2.2, 2.5)  | average #tokens: 485
wildchat_v1_8b_2048_default_template | score: 30.7  | 95% CI: (-2.8, 2.2)  | average #tokens: 756
phi-3-small-8k-instruct        | score: 29.8  | 95% CI: (-1.5, 2.2)  | average #tokens: 568
ta_chosen_llama3.1_instruct_dpo_2048 | score: 28.7  | 95% CI: (-2.1, 1.9)  | average #tokens: 662
wildchat_v2_8b_2048_default_template_3796 | score: 28.1  | 95% CI: (-2.2, 1.6)  | average #tokens: 787
ta_rejected_llama3.1_instruct_dpo_2048 | score: 28.0  | 95% CI: (-1.8, 2.3)  | average #tokens: 646
mistral-next                   | score: 27.4  | 95% CI: (-2.2, 2.3)  | average #tokens: 297
wildchat_v2_8b_2048_default_template_fullft_e5_9485 | score: 26.7  | 95% CI: (-1.9, 2.0)  | average #tokens: 699
wildchat_v2_8b_2048_default_template_full_sft | score: 26.5  | 95% CI: (-1.7, 2.1)  | average #tokens: 669
wildchat_v1_8b_2048_default_template_4000 | score: 25.5  | 95% CI: (-2.0, 2.0)  | average #tokens: 742
gpt-3.5-turbo-0613             | score: 24.8  | 95% CI: (-2.1, 2.0)  | average #tokens: 401
dbrx-instruct-preview          | score: 24.6  | 95% CI: (-1.7, 2.3)  | average #tokens: 415
claude-2.0                     | score: 24.0  | 95% CI: (-1.7, 2.0)  | average #tokens: 295
mixtral-8x7b-instruct-v0.1     | score: 23.4  | 95% CI: (-1.8, 2.2)  | average #tokens: 457
gpt-3.5-turbo-0125             | score: 23.3  | 95% CI: (-2.1, 2.3)  | average #tokens: 329
yi-34b-chat                    | score: 23.1  | 95% CI: (-1.8, 1.7)  | average #tokens: 611
starling-lm-7b-beta            | score: 23.0  | 95% CI: (-1.9, 2.0)  | average #tokens: 530
claude-2.1                     | score: 22.8  | 95% CI: (-1.6, 2.0)  | average #tokens: 290
llama-3.1-8b-instruct          | score: 21.3  | 95% CI: (-1.9, 1.4)  | average #tokens: 861
snorkel-mistral-pairrm-dpo     | score: 20.7  | 95% CI: (-1.9, 1.9)  | average #tokens: 564
llama-3-8b-instruct            | score: 20.6  | 95% CI: (-1.8, 1.9)  | average #tokens: 585
gpt-3.5-turbo-1106             | score: 18.9  | 95% CI: (-1.9, 1.9)  | average #tokens: 285
gpt-3.5-turbo-0314             | score: 18.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 334
gemini-pro                     | score: 17.8  | 95% CI: (-1.6, 1.6)  | average #tokens: 322
snowflake-arctic-instruct      | score: 17.6  | 95% CI: (-2.0, 1.9)  | average #tokens: 365
command-r                      | score: 17.0  | 95% CI: (-1.8, 1.7)  | average #tokens: 432
phi-3-mini-128k-instruct       | score: 15.4  | 95% CI: (-1.4, 1.5)  | average #tokens: 609
tulu-2-dpo-70b                 | score: 15.0  | 95% CI: (-1.8, 1.4)  | average #tokens: 550
starling-lm-7b-alpha           | score: 12.8  | 95% CI: (-1.6, 1.4)  | average #tokens: 483
mistral-7b-instruct            | score: 12.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 541
gemma-1.1-7b-it                | score: 12.1  | 95% CI: (-1.0, 1.3)  | average #tokens: 341
llama-2-70b-chat               | score: 11.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 595
vicuna-33b                     | score:  8.6  | 95% CI: (-1.4, 1.0)  | average #tokens: 451
gemma-7b-it                    | score:  7.5  | 95% CI: (-1.1, 1.1)  | average #tokens: 378
tulu_v2_8b_base_template_dpo   | score:  7.2  | 95% CI: (-0.9, 0.9)  | average #tokens: 496
tulu_v2_8b_bsz64_default_template_dpo | score:  7.0  | 95% CI: (-1.1, 1.3)  | average #tokens: 449
tulu_v2_8b_2048_default_template_dpo | score:  6.6  | 95% CI: (-0.9, 1.1)  | average #tokens: 463
tulu-2-dpo-7b                  | score:  6.0  | 95% CI: (-0.8, 0.9)  | average #tokens: 539
tulu_v2_8b_2048_default_template_sft | score:  5.1  | 95% CI: (-0.8, 1.0)  | average #tokens: 441
ta_chosen_tuluv2_dpo_2048_default_template | score:  4.7  | 95% CI: (-0.9, 0.9)  | average #tokens: 758
tulu_lora_sft_default_template_8b | score:  4.3  | 95% CI: (-0.8, 0.7)  | average #tokens: 444
tulu_lora_sft_base_template_8b | score:  4.3  | 95% CI: (-0.6, 0.8)  | average #tokens: 458
gemma-1.1-2b-it                | score:  3.4  | 95% CI: (-0.6, 0.7)  | average #tokens: 316
gemma-2b-it                    | score:  3.0  | 95% CI: (-0.7, 0.6)  | average #tokens: 369
tulu-2-7b                      | score:  2.5  | 95% CI: (-0.6, 0.6)  | average #tokens: 413
Meta-Llama-3.1-8B              | score:  0.5  | 95% CI: (-0.2, 0.3)  | average #tokens: 1616
所有任务已完成，vllm 服务已关闭。
运行时间: -28748992.98 分钟
----------------------------------------
执行参数: ta_chosen_tuluv2_dpo_2048_default_template
文件 data/arena-hard-v0.1/model_answer/ta_chosen_tuluv2_dpo_2048_default_template.jsonl 存在，跳过 vllm 服务启动和 gen_answer.py 执行。
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-0314, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Error code: 400 - {'error': {'message': "Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.", 'type': 'invalid_prompt', 'param': 'prompt', 'code': None}}
Namespace(bench_name='arena-hard-v0.1', judge_name='gpt-4-1106-preview', baseline='gpt-4-0314', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output=True, first_game_only=False)
Turning judgment results into battles...
gpt-4-turbo-2024-04-09         | score: 82.6  | 95% CI: (-1.4, 1.7)  | average #tokens: 662
claude-3-5-sonnet-20240620     | score: 79.3  | 95% CI: (-2.0, 1.8)  | average #tokens: 567
gpt-4o-2024-05-13              | score: 79.2  | 95% CI: (-2.1, 2.0)  | average #tokens: 696
gpt-4-0125-preview             | score: 78.0  | 95% CI: (-2.3, 1.8)  | average #tokens: 619
athene-70b                     | score: 76.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 683
gpt-4o-mini                    | score: 74.9  | 95% CI: (-1.8, 3.0)  | average #tokens: 668
gemini-1.5-pro-api-0514        | score: 72.0  | 95% CI: (-2.2, 2.2)  | average #tokens: 676
yi-large-preview               | score: 71.5  | 95% CI: (-2.1, 1.8)  | average #tokens: 720
mistral-large-2407             | score: 70.4  | 95% CI: (-2.1, 2.9)  | average #tokens: 623
llama-3.1-405b-instruct        | score: 64.1  | 95% CI: (-2.7, 2.0)  | average #tokens: 633
glm-4-0520                     | score: 63.8  | 95% CI: (-2.2, 2.5)  | average #tokens: 636
yi-large                       | score: 63.7  | 95% CI: (-2.7, 2.2)  | average #tokens: 626
deepseek-coder-v2              | score: 62.3  | 95% CI: (-2.3, 2.2)  | average #tokens: 578
claude-3-opus-20240229         | score: 60.4  | 95% CI: (-2.2, 2.2)  | average #tokens: 541
gemma-2-27b-it                 | score: 57.5  | 95% CI: (-2.9, 2.5)  | average #tokens: 577
llama-3.1-70b-instruct         | score: 55.7  | 95% CI: (-3.0, 2.6)  | average #tokens: 628
glm-4-0116                     | score: 55.7  | 95% CI: (-2.0, 2.1)  | average #tokens: 622
gemini-1.5-pro-api-0409-preview | score: 53.4  | 95% CI: (-2.2, 3.3)  | average #tokens: 478
glm-4-air                      | score: 50.9  | 95% CI: (-2.4, 2.7)  | average #tokens: 619
gpt-4-0314                     | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 423
gemini-1.5-flash-api-0514      | score: 49.6  | 95% CI: (-2.1, 2.6)  | average #tokens: 642
qwen2-72b-instruct             | score: 46.9  | 95% CI: (-2.3, 3.0)  | average #tokens: 515
claude-3-sonnet-20240229       | score: 46.8  | 95% CI: (-2.4, 1.6)  | average #tokens: 552
llama-3-70b-instruct           | score: 46.6  | 95% CI: (-2.5, 3.5)  | average #tokens: 591
wildchat_v2_8b_2048_default_template_fullft_lr5e6_e5_9485 | score: 42.9  | 95% CI: (-2.4, 2.1)  | average #tokens: 684
claude-3-haiku-20240307        | score: 41.5  | 95% CI: (-2.0, 2.4)  | average #tokens: 505
gpt-4-0613                     | score: 37.9  | 95% CI: (-2.9, 1.9)  | average #tokens: 354
mistral-large-2402             | score: 37.7  | 95% CI: (-2.5, 2.9)  | average #tokens: 400
Meta-Llama-3.1-8B-Instruct     | score: 37.5  | 95% CI: (-6.0, 5.9)  | average #tokens: 731
wildchat_v2_8b_2048_default_template_fullft_lr5e6_3794 | score: 36.9  | 95% CI: (-2.3, 2.3)  | average #tokens: 682
mixtral-8x22b-instruct-v0.1    | score: 36.4  | 95% CI: (-2.4, 2.5)  | average #tokens: 430
qwen1.5-72b-chat               | score: 36.1  | 95% CI: (-2.6, 2.0)  | average #tokens: 474
phi-3-medium-4k-instruct       | score: 33.4  | 95% CI: (-2.0, 2.4)  | average #tokens: 517
command-r-plus                 | score: 33.1  | 95% CI: (-2.6, 2.1)  | average #tokens: 541
mistral-medium                 | score: 31.9  | 95% CI: (-2.2, 2.5)  | average #tokens: 485
wildchat_v1_8b_2048_default_template | score: 30.7  | 95% CI: (-2.8, 2.2)  | average #tokens: 756
phi-3-small-8k-instruct        | score: 29.8  | 95% CI: (-1.5, 2.2)  | average #tokens: 568
ta_chosen_llama3.1_instruct_dpo_2048 | score: 28.7  | 95% CI: (-2.1, 1.9)  | average #tokens: 662
wildchat_v2_8b_2048_default_template_3796 | score: 28.1  | 95% CI: (-2.2, 1.6)  | average #tokens: 787
ta_rejected_llama3.1_instruct_dpo_2048 | score: 28.0  | 95% CI: (-1.8, 2.3)  | average #tokens: 646
mistral-next                   | score: 27.4  | 95% CI: (-2.2, 2.3)  | average #tokens: 297
wildchat_v2_8b_2048_default_template_fullft_e5_9485 | score: 26.7  | 95% CI: (-1.9, 2.0)  | average #tokens: 699
wildchat_v2_8b_2048_default_template_full_sft | score: 26.5  | 95% CI: (-1.7, 2.1)  | average #tokens: 669
wildchat_v1_8b_2048_default_template_4000 | score: 25.5  | 95% CI: (-2.0, 2.0)  | average #tokens: 742
gpt-3.5-turbo-0613             | score: 24.8  | 95% CI: (-2.1, 2.0)  | average #tokens: 401
dbrx-instruct-preview          | score: 24.6  | 95% CI: (-1.7, 2.3)  | average #tokens: 415
claude-2.0                     | score: 24.0  | 95% CI: (-1.7, 2.0)  | average #tokens: 295
mixtral-8x7b-instruct-v0.1     | score: 23.4  | 95% CI: (-1.8, 2.2)  | average #tokens: 457
gpt-3.5-turbo-0125             | score: 23.3  | 95% CI: (-2.1, 2.3)  | average #tokens: 329
yi-34b-chat                    | score: 23.1  | 95% CI: (-1.8, 1.7)  | average #tokens: 611
starling-lm-7b-beta            | score: 23.0  | 95% CI: (-1.9, 2.0)  | average #tokens: 530
claude-2.1                     | score: 22.8  | 95% CI: (-1.6, 2.0)  | average #tokens: 290
llama-3.1-8b-instruct          | score: 21.3  | 95% CI: (-1.9, 1.4)  | average #tokens: 861
snorkel-mistral-pairrm-dpo     | score: 20.7  | 95% CI: (-1.9, 1.9)  | average #tokens: 564
llama-3-8b-instruct            | score: 20.6  | 95% CI: (-1.8, 1.9)  | average #tokens: 585
gpt-3.5-turbo-1106             | score: 18.9  | 95% CI: (-1.9, 1.9)  | average #tokens: 285
gpt-3.5-turbo-0314             | score: 18.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 334
gemini-pro                     | score: 17.8  | 95% CI: (-1.6, 1.6)  | average #tokens: 322
snowflake-arctic-instruct      | score: 17.6  | 95% CI: (-2.0, 1.9)  | average #tokens: 365
command-r                      | score: 17.0  | 95% CI: (-1.8, 1.7)  | average #tokens: 432
phi-3-mini-128k-instruct       | score: 15.4  | 95% CI: (-1.4, 1.5)  | average #tokens: 609
tulu-2-dpo-70b                 | score: 15.0  | 95% CI: (-1.8, 1.4)  | average #tokens: 550
starling-lm-7b-alpha           | score: 12.8  | 95% CI: (-1.6, 1.4)  | average #tokens: 483
mistral-7b-instruct            | score: 12.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 541
gemma-1.1-7b-it                | score: 12.1  | 95% CI: (-1.0, 1.3)  | average #tokens: 341
llama-2-70b-chat               | score: 11.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 595
vicuna-33b                     | score:  8.6  | 95% CI: (-1.4, 1.0)  | average #tokens: 451
gemma-7b-it                    | score:  7.5  | 95% CI: (-1.1, 1.1)  | average #tokens: 378
tulu_v2_8b_base_template_dpo   | score:  7.2  | 95% CI: (-0.9, 0.9)  | average #tokens: 496
tulu_v2_8b_bsz64_default_template_dpo | score:  7.0  | 95% CI: (-1.1, 1.3)  | average #tokens: 449
tulu_v2_8b_2048_default_template_dpo | score:  6.6  | 95% CI: (-0.9, 1.1)  | average #tokens: 463
tulu-2-dpo-7b                  | score:  6.0  | 95% CI: (-0.8, 0.9)  | average #tokens: 539
tulu_v2_8b_2048_default_template_sft | score:  5.1  | 95% CI: (-0.8, 1.0)  | average #tokens: 441
ta_chosen_tuluv2_dpo_2048_default_template | score:  4.7  | 95% CI: (-0.9, 0.9)  | average #tokens: 758
tulu_lora_sft_default_template_8b | score:  4.3  | 95% CI: (-0.8, 0.7)  | average #tokens: 444
tulu_lora_sft_base_template_8b | score:  4.3  | 95% CI: (-0.6, 0.8)  | average #tokens: 458
gemma-1.1-2b-it                | score:  3.4  | 95% CI: (-0.6, 0.7)  | average #tokens: 316
gemma-2b-it                    | score:  3.0  | 95% CI: (-0.7, 0.6)  | average #tokens: 369
tulu-2-7b                      | score:  2.5  | 95% CI: (-0.6, 0.6)  | average #tokens: 413
Meta-Llama-3.1-8B              | score:  0.5  | 95% CI: (-0.2, 0.3)  | average #tokens: 1616
所有任务已完成，vllm 服务已关闭。
运行时间: -28749048.28 分钟
----------------------------------------
执行参数: ta_rejected_llama3.1_instruct_dpo_2048
文件 data/arena-hard-v0.1/model_answer/ta_rejected_llama3.1_instruct_dpo_2048.jsonl 存在，跳过 vllm 服务启动和 gen_answer.py 执行。
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-0314, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
Namespace(bench_name='arena-hard-v0.1', judge_name='gpt-4-1106-preview', baseline='gpt-4-0314', load_battles=False, load_bootstrap=False, show_elo=False, weight=3, num_rounds=100, output=True, first_game_only=False)
Turning judgment results into battles...
gpt-4-turbo-2024-04-09         | score: 82.6  | 95% CI: (-1.4, 1.7)  | average #tokens: 662
claude-3-5-sonnet-20240620     | score: 79.3  | 95% CI: (-2.0, 1.8)  | average #tokens: 567
gpt-4o-2024-05-13              | score: 79.2  | 95% CI: (-2.1, 2.0)  | average #tokens: 696
gpt-4-0125-preview             | score: 78.0  | 95% CI: (-2.3, 1.8)  | average #tokens: 619
athene-70b                     | score: 76.8  | 95% CI: (-1.9, 1.9)  | average #tokens: 683
gpt-4o-mini                    | score: 74.9  | 95% CI: (-1.8, 3.0)  | average #tokens: 668
gemini-1.5-pro-api-0514        | score: 72.0  | 95% CI: (-2.2, 2.2)  | average #tokens: 676
yi-large-preview               | score: 71.5  | 95% CI: (-2.1, 1.8)  | average #tokens: 720
mistral-large-2407             | score: 70.4  | 95% CI: (-2.1, 2.9)  | average #tokens: 623
llama-3.1-405b-instruct        | score: 64.1  | 95% CI: (-2.7, 2.0)  | average #tokens: 633
glm-4-0520                     | score: 63.8  | 95% CI: (-2.2, 2.5)  | average #tokens: 636
yi-large                       | score: 63.7  | 95% CI: (-2.7, 2.2)  | average #tokens: 626
deepseek-coder-v2              | score: 62.3  | 95% CI: (-2.3, 2.2)  | average #tokens: 578
claude-3-opus-20240229         | score: 60.4  | 95% CI: (-2.2, 2.2)  | average #tokens: 541
gemma-2-27b-it                 | score: 57.5  | 95% CI: (-2.9, 2.5)  | average #tokens: 577
llama-3.1-70b-instruct         | score: 55.7  | 95% CI: (-3.0, 2.6)  | average #tokens: 628
glm-4-0116                     | score: 55.7  | 95% CI: (-2.0, 2.1)  | average #tokens: 622
gemini-1.5-pro-api-0409-preview | score: 53.4  | 95% CI: (-2.2, 3.3)  | average #tokens: 478
glm-4-air                      | score: 50.9  | 95% CI: (-2.4, 2.7)  | average #tokens: 619
gpt-4-0314                     | score: 50.0  | 95% CI:  (0.0, 0.0)  | average #tokens: 423
gemini-1.5-flash-api-0514      | score: 49.6  | 95% CI: (-2.1, 2.6)  | average #tokens: 642
qwen2-72b-instruct             | score: 46.9  | 95% CI: (-2.3, 3.0)  | average #tokens: 515
claude-3-sonnet-20240229       | score: 46.8  | 95% CI: (-2.4, 1.6)  | average #tokens: 552
llama-3-70b-instruct           | score: 46.6  | 95% CI: (-2.5, 3.5)  | average #tokens: 591
wildchat_v2_8b_2048_default_template_fullft_lr5e6_e5_9485 | score: 42.9  | 95% CI: (-2.4, 2.1)  | average #tokens: 684
claude-3-haiku-20240307        | score: 41.5  | 95% CI: (-2.0, 2.4)  | average #tokens: 505
gpt-4-0613                     | score: 37.9  | 95% CI: (-2.9, 1.9)  | average #tokens: 354
mistral-large-2402             | score: 37.7  | 95% CI: (-2.5, 2.9)  | average #tokens: 400
Meta-Llama-3.1-8B-Instruct     | score: 37.5  | 95% CI: (-6.0, 5.9)  | average #tokens: 731
wildchat_v2_8b_2048_default_template_fullft_lr5e6_3794 | score: 36.9  | 95% CI: (-2.3, 2.3)  | average #tokens: 682
mixtral-8x22b-instruct-v0.1    | score: 36.4  | 95% CI: (-2.4, 2.5)  | average #tokens: 430
qwen1.5-72b-chat               | score: 36.1  | 95% CI: (-2.6, 2.0)  | average #tokens: 474
phi-3-medium-4k-instruct       | score: 33.4  | 95% CI: (-2.0, 2.4)  | average #tokens: 517
command-r-plus                 | score: 33.1  | 95% CI: (-2.6, 2.1)  | average #tokens: 541
mistral-medium                 | score: 31.9  | 95% CI: (-2.2, 2.5)  | average #tokens: 485
wildchat_v1_8b_2048_default_template | score: 30.7  | 95% CI: (-2.8, 2.2)  | average #tokens: 756
phi-3-small-8k-instruct        | score: 29.8  | 95% CI: (-1.5, 2.2)  | average #tokens: 568
ta_chosen_llama3.1_instruct_dpo_2048 | score: 28.7  | 95% CI: (-2.1, 1.9)  | average #tokens: 662
wildchat_v2_8b_2048_default_template_3796 | score: 28.1  | 95% CI: (-2.2, 1.6)  | average #tokens: 787
ta_rejected_llama3.1_instruct_dpo_2048 | score: 28.0  | 95% CI: (-1.8, 2.3)  | average #tokens: 646
mistral-next                   | score: 27.4  | 95% CI: (-2.2, 2.3)  | average #tokens: 297
wildchat_v2_8b_2048_default_template_fullft_e5_9485 | score: 26.7  | 95% CI: (-1.9, 2.0)  | average #tokens: 699
wildchat_v2_8b_2048_default_template_full_sft | score: 26.5  | 95% CI: (-1.7, 2.1)  | average #tokens: 669
wildchat_v1_8b_2048_default_template_4000 | score: 25.5  | 95% CI: (-2.0, 2.0)  | average #tokens: 742
gpt-3.5-turbo-0613             | score: 24.8  | 95% CI: (-2.1, 2.0)  | average #tokens: 401
dbrx-instruct-preview          | score: 24.6  | 95% CI: (-1.7, 2.3)  | average #tokens: 415
claude-2.0                     | score: 24.0  | 95% CI: (-1.7, 2.0)  | average #tokens: 295
mixtral-8x7b-instruct-v0.1     | score: 23.4  | 95% CI: (-1.8, 2.2)  | average #tokens: 457
gpt-3.5-turbo-0125             | score: 23.3  | 95% CI: (-2.1, 2.3)  | average #tokens: 329
yi-34b-chat                    | score: 23.1  | 95% CI: (-1.8, 1.7)  | average #tokens: 611
starling-lm-7b-beta            | score: 23.0  | 95% CI: (-1.9, 2.0)  | average #tokens: 530
claude-2.1                     | score: 22.8  | 95% CI: (-1.6, 2.0)  | average #tokens: 290
llama-3.1-8b-instruct          | score: 21.3  | 95% CI: (-1.9, 1.4)  | average #tokens: 861
snorkel-mistral-pairrm-dpo     | score: 20.7  | 95% CI: (-1.9, 1.9)  | average #tokens: 564
llama-3-8b-instruct            | score: 20.6  | 95% CI: (-1.8, 1.9)  | average #tokens: 585
gpt-3.5-turbo-1106             | score: 18.9  | 95% CI: (-1.9, 1.9)  | average #tokens: 285
gpt-3.5-turbo-0314             | score: 18.1  | 95% CI: (-1.9, 1.4)  | average #tokens: 334
gemini-pro                     | score: 17.8  | 95% CI: (-1.6, 1.6)  | average #tokens: 322
snowflake-arctic-instruct      | score: 17.6  | 95% CI: (-2.0, 1.9)  | average #tokens: 365
command-r                      | score: 17.0  | 95% CI: (-1.8, 1.7)  | average #tokens: 432
phi-3-mini-128k-instruct       | score: 15.4  | 95% CI: (-1.4, 1.5)  | average #tokens: 609
tulu-2-dpo-70b                 | score: 15.0  | 95% CI: (-1.8, 1.4)  | average #tokens: 550
starling-lm-7b-alpha           | score: 12.8  | 95% CI: (-1.6, 1.4)  | average #tokens: 483
mistral-7b-instruct            | score: 12.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 541
gemma-1.1-7b-it                | score: 12.1  | 95% CI: (-1.0, 1.3)  | average #tokens: 341
llama-2-70b-chat               | score: 11.6  | 95% CI: (-1.2, 1.3)  | average #tokens: 595
vicuna-33b                     | score:  8.6  | 95% CI: (-1.4, 1.0)  | average #tokens: 451
gemma-7b-it                    | score:  7.5  | 95% CI: (-1.1, 1.1)  | average #tokens: 378
tulu_v2_8b_base_template_dpo   | score:  7.2  | 95% CI: (-0.9, 0.9)  | average #tokens: 496
tulu_v2_8b_bsz64_default_template_dpo | score:  7.0  | 95% CI: (-1.1, 1.3)  | average #tokens: 449
tulu_v2_8b_2048_default_template_dpo | score:  6.6  | 95% CI: (-0.9, 1.1)  | average #tokens: 463
tulu-2-dpo-7b                  | score:  6.0  | 95% CI: (-0.8, 0.9)  | average #tokens: 539
tulu_v2_8b_2048_default_template_sft | score:  5.1  | 95% CI: (-0.8, 1.0)  | average #tokens: 441
ta_chosen_tuluv2_dpo_2048_default_template | score:  4.7  | 95% CI: (-0.9, 0.9)  | average #tokens: 758
tulu_lora_sft_default_template_8b | score:  4.3  | 95% CI: (-0.8, 0.7)  | average #tokens: 444
tulu_lora_sft_base_template_8b | score:  4.3  | 95% CI: (-0.6, 0.8)  | average #tokens: 458
gemma-1.1-2b-it                | score:  3.4  | 95% CI: (-0.6, 0.7)  | average #tokens: 316
gemma-2b-it                    | score:  3.0  | 95% CI: (-0.7, 0.6)  | average #tokens: 369
tulu-2-7b                      | score:  2.5  | 95% CI: (-0.6, 0.6)  | average #tokens: 413
Meta-Llama-3.1-8B              | score:  0.5  | 95% CI: (-0.2, 0.3)  | average #tokens: 1616
所有任务已完成，vllm 服务已关闭。
运行时间: -28749095.58 分钟
----------------------------------------
执行参数: tulu_lora_sft_default_template_8b
文件 data/arena-hard-v0.1/model_answer/tulu_lora_sft_default_template_8b.jsonl 存在，跳过 vllm 服务启动和 gen_answer.py 执行。
Namespace(setting_file='config/judge_config.yaml', endpoint_file='config/api_config.yaml')
judge model: gpt-4o, baseline: True, baseline model: gpt-4-0314, reference: False, reference models: None, temperature: 0, max tokens: 4096, pairwise: True
