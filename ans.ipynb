{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    \"\"\"  \n",
    "    读取 JSONL 文件中的数据并返回一个包含所有记录的字典列表。  \n",
    "  \n",
    "    参数:  \n",
    "    file_path (str): JSONL 文件的路径。  \n",
    "  \n",
    "    返回:  \n",
    "    list: 包含所有记录的字典列表。  \n",
    "    \"\"\"  \n",
    "    data = []  \n",
    "  \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:  \n",
    "        for line in file:  \n",
    "            # 解析每一行的 JSON 对象并添加到列表中  \n",
    "            data.append(json.loads(line.strip()))  \n",
    "  \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen2-72B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-8B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-70B-Instruct_sample.json\n",
      "Model: tulu-2-dpo-70b_sample.json\n",
      "Merged results saved to merged_results.csv\n",
      "Label results text saved to label_results_text.csv\n",
      "Label results image saved to label_results_image.csv\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import os  \n",
    "import pandas as pd  \n",
    "  \n",
    "def calculate(data):  \n",
    "    good_idx = []  \n",
    "    same_idx = []  \n",
    "    loss_idx = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"score_1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"score_2\"]]  \n",
    "        if score_1 != score_2:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_2 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def cal_text(data):  \n",
    "    model_name = data[0][\"model_id_2\"]  \n",
    "    judge_data = read_jsonl(f\"data/arena-ta/model_judgment/gpt-4o_text/{model_name}.jsonl\")  \n",
    "    judge_dict = {item['question_id']: [item['games'][0]['score'], item['games'][0]['judgment'], item['games'][1]['score'], item['games'][1]['judgment']] for item in judge_data}  \n",
    "    res = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data):  \n",
    "        score_1 = judge_dict[item[\"question_id\"]][0]  \n",
    "        judge_1 = judge_dict[item[\"question_id\"]][1]  \n",
    "        score_2 = judge_dict[item[\"question_id\"]][2]  \n",
    "        judge_2 = judge_dict[item[\"question_id\"]][3]  \n",
    "        item[\"text_score1\"] = score_1  \n",
    "        item[\"text_judge1\"] = judge_1  \n",
    "        item[\"text_score2\"] = score_2  \n",
    "        item[\"text_judge2\"] = judge_2  \n",
    "        good_idx = []  \n",
    "        same_idx = []  \n",
    "        loss_idx = []  \n",
    "        res.append(item)  \n",
    "    for idx, item in enumerate(res[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"text_score1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"text_score2\"]]  \n",
    "        if score_1 != score_2:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_2 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    with open(file_path, 'r') as file:  \n",
    "        return [json.loads(line) for line in file]  \n",
    "  \n",
    "def merge_results(model_name, image_res, text_res):  \n",
    "    merged_result = {  \n",
    "        \"model\": model_name,  # 添加模型名称到结果字典的第一项  \n",
    "        \"good_idx_image\": image_res[\"good_idx\"],  \n",
    "        \"same_idx_image\": image_res[\"same_idx\"],  \n",
    "        \"loss_idx_image\": image_res[\"loss_idx\"],  \n",
    "        \"sum_image\": image_res[\"sum\"],  \n",
    "        \"good_idx_text\": text_res[\"good_idx\"],  \n",
    "        \"same_idx_text\": text_res[\"same_idx\"],  \n",
    "        \"loss_idx_text\": text_res[\"loss_idx\"],  \n",
    "        \"sum_text\": text_res[\"sum\"]  \n",
    "    }  \n",
    "    return merged_result  \n",
    "  \n",
    "# 获取data/annotation/目录下的所有文件  \n",
    "annotation_dir = 'data/annotation_2/'  \n",
    "files = [f for f in os.listdir(annotation_dir) if os.path.isfile(os.path.join(annotation_dir, f))]  \n",
    "  \n",
    "merged_results = []  \n",
    "label_results_text = {}  \n",
    "label_results_image = {}  \n",
    "  \n",
    "# 遍历每个文件并进行calculate统计  \n",
    "for file_name in files:  \n",
    "    file_path = os.path.join(annotation_dir, file_name)  \n",
    "    with open(file_path, 'r') as f:  \n",
    "        data = json.load(f)  \n",
    "    print(f\"Model: {file_name}\")  \n",
    "    res, result_label_image = calculate(data)  \n",
    "    res_text, result_label_text = cal_text(data)  \n",
    "    merged_res = merge_results(file_name, res, res_text)  # 传递模型名称  \n",
    "    merged_results.append(merged_res)  \n",
    "    model_name = file_name.split(\"_\")[0]  \n",
    "    label_results_text[model_name] = result_label_text  \n",
    "    label_results_image[model_name] = result_label_image  \n",
    "  \n",
    "# 指定的模型顺序  \n",
    "model_order = [\"Meta-Llama-3.1-8B-Instruct\", \"Meta-Llama-3.1-70B-Instruct\", \"Qwen2-72B-Instruct\", \"tulu-2-dpo-70b\"]  \n",
    "  \n",
    "# 按指定顺序排序 merged_results  \n",
    "ordered_merged_results = sorted(merged_results, key=lambda x: model_order.index(x[\"model\"]) if x[\"model\"] in model_order else float('inf'))  \n",
    "  \n",
    "# 创建一个DataFrame并保存为CSV文件  \n",
    "df = pd.DataFrame(ordered_merged_results)  \n",
    "  \n",
    "# 确保模型名称是第一列  \n",
    "df = df[[\"model\", \"good_idx_image\", \"same_idx_image\", \"loss_idx_image\", \"sum_image\", \"good_idx_text\", \"same_idx_text\", \"loss_idx_text\", \"sum_text\"]]  \n",
    "  \n",
    "df.to_csv(\"merged_results.csv\", index=False)  \n",
    "print(\"Merged results saved to merged_results.csv\")  \n",
    "  \n",
    "# 保存 label_results_text 为 CSV 文件  \n",
    "label_text_df = pd.DataFrame.from_dict(label_results_text, orient='index').transpose()  \n",
    "label_text_df = label_text_df[model_order]  \n",
    "label_text_df.to_csv(\"label_results_text.csv\", index=False)  \n",
    "print(\"Label results text saved to label_results_text.csv\")  \n",
    "  \n",
    "# 保存 label_results_image 为 CSV 文件  \n",
    "label_image_df = pd.DataFrame.from_dict(label_results_image, orient='index').transpose()  \n",
    "label_image_df = label_image_df[model_order]  \n",
    "label_image_df.to_csv(\"label_results_image.csv\", index=False)  \n",
    "print(\"Label results image saved to label_results_image.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen2-72B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-8B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-70B-Instruct_sample.json\n",
      "Model: tulu-2-dpo-70b_sample.json\n",
      "Merged results saved to merged_results.csv\n",
      "Label results text saved to label_results_text.csv\n",
      "Label results image saved to label_results_image.csv\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import os  \n",
    "import pandas as pd  \n",
    "  \n",
    "def calculate(data):  \n",
    "    good_idx = []  \n",
    "    same_idx = []  \n",
    "    loss_idx = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"score_1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"score_2\"]]  \n",
    "        if score_1 != score_2: \n",
    "            if score_1 == 3 and score_2 == 2:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\") \n",
    "            elif score_1 == 1 and score_2 == 2:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            elif score_1 == 2 and score_2 == 3:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\")\n",
    "            elif score_1 == 2 and score_2 == 1:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            else:\n",
    "                same_idx.append(idx)  \n",
    "                result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_1 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def cal_text(data):  \n",
    "    model_name = data[0][\"model_id_2\"]  \n",
    "    judge_data = read_jsonl(f\"data/arena-ta/model_judgment/gpt-4o_text/{model_name}.jsonl\")  \n",
    "    judge_dict = {item['question_id']: [item['games'][0]['score'], item['games'][0]['judgment'], item['games'][1]['score'], item['games'][1]['judgment']] for item in judge_data}  \n",
    "    res = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data):  \n",
    "        score_1 = judge_dict[item[\"question_id\"]][0]  \n",
    "        judge_1 = judge_dict[item[\"question_id\"]][1]  \n",
    "        score_2 = judge_dict[item[\"question_id\"]][2]  \n",
    "        judge_2 = judge_dict[item[\"question_id\"]][3]  \n",
    "        item[\"text_score1\"] = score_1  \n",
    "        item[\"text_judge1\"] = judge_1  \n",
    "        item[\"text_score2\"] = score_2  \n",
    "        item[\"text_judge2\"] = judge_2  \n",
    "        good_idx = []  \n",
    "        same_idx = []  \n",
    "        loss_idx = []  \n",
    "        res.append(item)  \n",
    "    for idx, item in enumerate(res[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"text_score1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"text_score2\"]]  \n",
    "        if score_1 != score_2: \n",
    "            if score_1 == 3 and score_2 == 2:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\") \n",
    "            elif score_1 == 1 and score_2 == 2:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            elif score_1 == 2 and score_2 == 3:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\")\n",
    "            elif score_1 == 2 and score_2 == 1:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            else:\n",
    "                same_idx.append(idx)  \n",
    "                result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_1 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    with open(file_path, 'r') as file:  \n",
    "        return [json.loads(line) for line in file]  \n",
    "  \n",
    "def merge_results(model_name, image_res, text_res):  \n",
    "    merged_result = {  \n",
    "        \"model\": model_name,  # 添加模型名称到结果字典的第一项  \n",
    "        \"good_idx_image\": image_res[\"good_idx\"],  \n",
    "        \"same_idx_image\": image_res[\"same_idx\"],  \n",
    "        \"loss_idx_image\": image_res[\"loss_idx\"],  \n",
    "        \"sum_image\": image_res[\"sum\"],  \n",
    "        \"good_idx_text\": text_res[\"good_idx\"],  \n",
    "        \"same_idx_text\": text_res[\"same_idx\"],  \n",
    "        \"loss_idx_text\": text_res[\"loss_idx\"],  \n",
    "        \"sum_text\": text_res[\"sum\"]  \n",
    "    }  \n",
    "    return merged_result  \n",
    "  \n",
    "# 获取data/annotation/目录下的所有文件  \n",
    "annotation_dir = 'data/annotation_2/'  \n",
    "files = [f for f in os.listdir(annotation_dir) if os.path.isfile(os.path.join(annotation_dir, f))]  \n",
    "  \n",
    "merged_results = []  \n",
    "label_results_text = {}  \n",
    "label_results_image = {}  \n",
    "  \n",
    "# 遍历每个文件并进行calculate统计  \n",
    "for file_name in files:  \n",
    "    file_path = os.path.join(annotation_dir, file_name)  \n",
    "    with open(file_path, 'r') as f:  \n",
    "        data = json.load(f)  \n",
    "    print(f\"Model: {file_name}\")  \n",
    "    res, result_label_image = calculate(data)  \n",
    "    res_text, result_label_text = cal_text(data)  \n",
    "    merged_res = merge_results(file_name, res, res_text)  # 传递模型名称  \n",
    "    merged_results.append(merged_res)  \n",
    "    model_name = file_name.split(\"_\")[0]  \n",
    "    label_results_text[model_name] = result_label_text  \n",
    "    label_results_image[model_name] = result_label_image  \n",
    "  \n",
    "# 指定的模型顺序  \n",
    "model_order = [\"Meta-Llama-3.1-8B-Instruct\", \"Meta-Llama-3.1-70B-Instruct\", \"Qwen2-72B-Instruct\", \"tulu-2-dpo-70b\"]  \n",
    "  \n",
    "# 按指定顺序排序 merged_results  \n",
    "ordered_merged_results = sorted(merged_results, key=lambda x: model_order.index(x[\"model\"]) if x[\"model\"] in model_order else float('inf'))  \n",
    "  \n",
    "# 创建一个DataFrame并保存为CSV文件  \n",
    "df = pd.DataFrame(ordered_merged_results)  \n",
    "  \n",
    "# 确保模型名称是第一列  \n",
    "df = df[[\"model\", \"good_idx_image\", \"same_idx_image\", \"loss_idx_image\", \"sum_image\", \"good_idx_text\", \"same_idx_text\", \"loss_idx_text\", \"sum_text\"]]  \n",
    "  \n",
    "df.to_csv(\"merged_results2.csv\", index=False)  \n",
    "print(\"Merged results saved to merged_results.csv\")  \n",
    "  \n",
    "# 保存 label_results_text 为 CSV 文件  \n",
    "label_text_df = pd.DataFrame.from_dict(label_results_text, orient='index').transpose()  \n",
    "label_text_df = label_text_df[model_order]  \n",
    "label_text_df.to_csv(\"label_results_text2.csv\", index=False)  \n",
    "print(\"Label results text saved to label_results_text.csv\")  \n",
    "  \n",
    "# 保存 label_results_image 为 CSV 文件  \n",
    "label_image_df = pd.DataFrame.from_dict(label_results_image, orient='index').transpose()  \n",
    "label_image_df = label_image_df[model_order]  \n",
    "label_image_df.to_csv(\"label_results_image2.csv\", index=False)  \n",
    "print(\"Label results image saved to label_results_image.csv\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
