{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    \"\"\"  \n",
    "    读取 JSONL 文件中的数据并返回一个包含所有记录的字典列表。  \n",
    "  \n",
    "    参数:  \n",
    "    file_path (str): JSONL 文件的路径。  \n",
    "  \n",
    "    返回:  \n",
    "    list: 包含所有记录的字典列表。  \n",
    "    \"\"\"  \n",
    "    data = []  \n",
    "  \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:  \n",
    "        for line in file:  \n",
    "            # 解析每一行的 JSON 对象并添加到列表中  \n",
    "            data.append(json.loads(line.strip()))  \n",
    "  \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_judges: 1\n",
      "same_judges: 284\n",
      "different_judges: 152\n",
      "good_samples: 45\n",
      "model_name: Meta-Llama-3.1-8B-Instruct, len: 50\n",
      "null_judges: 0\n",
      "same_judges: 287\n",
      "different_judges: 139\n",
      "good_samples: 55\n",
      "model_name: Meta-Llama-3.1-70B-Instruct, len: 50\n",
      "null_judges: 0\n",
      "same_judges: 388\n",
      "different_judges: 93\n",
      "good_samples: 24\n",
      "model_name: tulu-2-dpo-70b, len: 50\n",
      "null_judges: 0\n",
      "same_judges: 398\n",
      "different_judges: 79\n",
      "good_samples: 36\n",
      "model_name: Qwen2-72B-Instruct, len: 50\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json  \n",
    "import pandas as pd  \n",
    "  \n",
    "# 读取JSON文件  \n",
    "ana = \"data/annotation/Meta-Llama-3.1-8B-Instruct_sample.json\"  \n",
    "with open(ana, \"r\") as f:  \n",
    "    data = json.load(f)  \n",
    "  \n",
    "# 创建字典  \n",
    "# judge_dict = {item['question_id']: [item['query']] for item in data}  \n",
    "question = [item[\"question_id\"] for item in data]\n",
    "\n",
    "# 创建DataFrame  \n",
    "df = pd.DataFrame(question, columns=[\"question_id\"])  \n",
    "  \n",
    "# 保存到CSV文件  \n",
    "# df.to_csv(\"data/sample_query/sample_query.csv\", index=False)  \n",
    "random_indices = question\n",
    "# random_indices = [item[\"question_id\"] for item in question_id]\n",
    "def get_judge_answer(model_name):\n",
    "    # data = read_jsonl(\"data/alpaca/model_judgment/gpt-4o_images/tulu_v2_8b_2048_default_template_dpo.jsonl\")\n",
    "    data = read_jsonl(f\"data/arena-ta/model_judgment/gpt-4o_images/{model_name}.jsonl\")\n",
    "    model_answer1 = read_jsonl(\"data/arena-ta/model_answer/gpt-4-1106-preview.jsonl\") # baseline answer\n",
    "    model_answer2 = read_jsonl(f\"data/arena-ta/model_answer/{model_name}.jsonl\")\n",
    "    question = read_jsonl(f\"data/arena-ta/question.jsonl\")\n",
    "    question_dict = {item[\"question_id\"]: {\"cluster\":item[\"cluster\"], \"query\":item[\"turns\"][0][\"content\"]} for item in question}\n",
    "    # data = read_jsonl(\"data/alpaca/model_judgment/gpt-4o/Meta-Llama-3.1-8B-Instruct.jsonl\")\n",
    "    # data = read_jsonl(\"data/arena-hard-v0.1/model_judgment/gpt-4o/Meta-Llama-3.1-8B-Instruct.jsonl\")\n",
    "    score_A = [item['games'][0]['score'] for item in data]\n",
    "    score_B = [item['games'][1]['score'] for item in data]\n",
    "    score_all = [[x1, x2] for x1, x2 in zip(score_A, score_B)]\n",
    "    score_all\n",
    "    score_map = {\n",
    "        \"A>>B\": 5,\n",
    "        \"A>B\": 4,\n",
    "        \"A=B\": 3,\n",
    "        \"B>A\": 2,\n",
    "        \"B>>A\": 1,\n",
    "        None:0\n",
    "    }\n",
    "    score_map_generall = {\n",
    "        \"A>>B\": 3,\n",
    "        \"A>B\": 3,\n",
    "        \"A=B\": 2,\n",
    "        \"B>A\": 1,\n",
    "        \"B>>A\": 1,\n",
    "        None:0\n",
    "    }\n",
    "    score_all_quant = [[score_map[x1], score_map[x2]] for x1, x2 in score_all]\n",
    "    score_generall = [[score_map_generall[x1], score_map_generall[x2]] for x1, x2 in score_all]\n",
    "    null_judges = []\n",
    "    for i, (x1, x2) in enumerate(score_all_quant):\n",
    "        if x1 == 0 or x2 == 0:\n",
    "            null_judges.append(i)\n",
    "    print(f\"null_judges: {len(null_judges)}\")\n",
    "    same_judges = []\n",
    "    different_judges = []\n",
    "    for i, (x1, x2) in enumerate(score_generall):\n",
    "        if (x1 == 1 and x2 == 3) or (x1 == 3 and x2 == 1) or (x1 == 2 and x2 == 2):\n",
    "            same_judges.append(i)\n",
    "        if (x1 == x2 and x1 != 2):\n",
    "            different_judges.append(i)\n",
    "    print(f\"same_judges: {len(same_judges)}\")\n",
    "    print(f\"different_judges: {len(different_judges)}\")\n",
    "    good_samples = []\n",
    "    for i, (x1, x2) in enumerate(score_generall):\n",
    "        if x1 == 1 and x2 == 3:\n",
    "            good_samples.append(i)\n",
    "    print(f\"good_samples: {len(good_samples)}\")\n",
    "    judge_dict = {item['question_id']:[item['games'][0]['score'], item['games'][0]['judgment'], item['games'][1]['score'], item['games'][1]['judgment']]  for item in data}\n",
    "    model_answer1_dict = {item['question_id']:[item['choices'][0]['turns'][0]['content'], item['choices'][0]['turns'][0]['token_len'], item['model_id']]  for item in model_answer1}\n",
    "    model_answer2_dict = {item['question_id']:[item['choices'][0]['turns'][0]['content'], item['choices'][0]['turns'][0]['token_len'], item['model_id']]  for item in model_answer2}\n",
    "    res = []\n",
    "    index = 0\n",
    "    # for index, idx in enumerate(good_samples):\n",
    "    # for index, idx in enumerate(good_samples):\n",
    "    # random_indices = random.sample(range(len(data)), 50)  \n",
    "\n",
    "  \n",
    "    for index, idx in enumerate(random_indices):\n",
    "        question_id = idx\n",
    "        # if score != judge_dict[question_id][0]:\n",
    "        res.append({\n",
    "            \"index\": index,\n",
    "            \"question_id\":question_id, \n",
    "            \"query\": question_dict[question_id][\"query\"],\n",
    "            \"cluster\": question_dict[question_id][\"cluster\"],\n",
    "            \"score_1\":judge_dict[question_id][0], \n",
    "            \"score_2\":judge_dict[question_id][2], \n",
    "            \"judgment_1\":judge_dict[question_id][1], \n",
    "            \"judgment_2\":judge_dict[question_id][3],\n",
    "            \"model_answer1\": model_answer1_dict[question_id][0],\n",
    "            \"token_len1\": model_answer1_dict[question_id][1],\n",
    "            \"model_id_1\":model_answer1_dict[question_id][2],\n",
    "            \"model_answer2\": model_answer2_dict[question_id][0],\n",
    "            \"token_len2\": model_answer2_dict[question_id][1],\n",
    "            \"model_id_2\":model_answer2_dict[question_id][2],\n",
    "            })\n",
    "    return res\n",
    "# model_name = \"tulu_v2_8b_default_template_dpo_list_bsz1_trible_debug\"\n",
    "# res = get_judge_answer(model_name)\n",
    "# Model list  \n",
    "# model_list = [\"ta_llama3_instruct_dpo_list_bsz1_trible_debug_v2-1500\", \"Meta-Llama-3.1-8B-Instruct\", \"Meta-Llama-3.1-70B-Instruct\", \"tulu-2-dpo-70b\", \"Qwen2-72B-Instruct\"]  # Replace with actual model names  \n",
    "\n",
    "model_list = [\"Meta-Llama-3.1-8B-Instruct\", \"Meta-Llama-3.1-70B-Instruct\", \"tulu-2-dpo-70b\", \"Qwen2-72B-Instruct\"]  # Replace with actual model names  \n",
    "# Loop through each model and get 50 random samples  \n",
    "for model_name in model_list:  \n",
    "    res = get_judge_answer(model_name)  \n",
    "    print(f\"model_name: {model_name}, len: {len(res)}\")\n",
    "    # random_samples = random.sample(res, 50) \n",
    "    with open(f\"data/annotation_2/{model_name}_sample.json\", 'w') as f:\n",
    "        json.dump(res, f, indent=4)  \n",
    "    # generate_res(res, model_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen2-72B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-8B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-70B-Instruct_sample.json\n",
      "Model: tulu-2-dpo-70b_sample.json\n",
      "Merged results saved to merged_results.csv\n",
      "Label results text saved to label_results_text.csv\n",
      "Label results image saved to label_results_image.csv\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import os  \n",
    "import pandas as pd  \n",
    "  \n",
    "def calculate(data):  \n",
    "    good_idx = []  \n",
    "    same_idx = []  \n",
    "    loss_idx = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"score_1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"score_2\"]]  \n",
    "        if score_1 != score_2:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_2 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def cal_text(data):  \n",
    "    model_name = data[0][\"model_id_2\"]  \n",
    "    judge_data = read_jsonl(f\"data/arena-ta/model_judgment/gpt-4o_text/{model_name}.jsonl\")  \n",
    "    judge_dict = {item['question_id']: [item['games'][0]['score'], item['games'][0]['judgment'], item['games'][1]['score'], item['games'][1]['judgment']] for item in judge_data}  \n",
    "    res = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data):  \n",
    "        score_1 = judge_dict[item[\"question_id\"]][0]  \n",
    "        judge_1 = judge_dict[item[\"question_id\"]][1]  \n",
    "        score_2 = judge_dict[item[\"question_id\"]][2]  \n",
    "        judge_2 = judge_dict[item[\"question_id\"]][3]  \n",
    "        item[\"text_score1\"] = score_1  \n",
    "        item[\"text_judge1\"] = judge_1  \n",
    "        item[\"text_score2\"] = score_2  \n",
    "        item[\"text_judge2\"] = judge_2  \n",
    "        good_idx = []  \n",
    "        same_idx = []  \n",
    "        loss_idx = []  \n",
    "        res.append(item)  \n",
    "    for idx, item in enumerate(res[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"text_score1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"text_score2\"]]  \n",
    "        if score_1 != score_2:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_2 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    with open(file_path, 'r') as file:  \n",
    "        return [json.loads(line) for line in file]  \n",
    "  \n",
    "def merge_results(model_name, image_res, text_res):  \n",
    "    merged_result = {  \n",
    "        \"model\": model_name,  # 添加模型名称到结果字典的第一项  \n",
    "        \"good_idx_image\": image_res[\"good_idx\"],  \n",
    "        \"same_idx_image\": image_res[\"same_idx\"],  \n",
    "        \"loss_idx_image\": image_res[\"loss_idx\"],  \n",
    "        \"sum_image\": image_res[\"sum\"],  \n",
    "        \"good_idx_text\": text_res[\"good_idx\"],  \n",
    "        \"same_idx_text\": text_res[\"same_idx\"],  \n",
    "        \"loss_idx_text\": text_res[\"loss_idx\"],  \n",
    "        \"sum_text\": text_res[\"sum\"]  \n",
    "    }  \n",
    "    return merged_result  \n",
    "  \n",
    "# 获取data/annotation/目录下的所有文件  \n",
    "annotation_dir = 'data/annotation_2/'  \n",
    "files = [f for f in os.listdir(annotation_dir) if os.path.isfile(os.path.join(annotation_dir, f))]  \n",
    "  \n",
    "merged_results = []  \n",
    "label_results_text = {}  \n",
    "label_results_image = {}  \n",
    "  \n",
    "# 遍历每个文件并进行calculate统计  \n",
    "for file_name in files:  \n",
    "    file_path = os.path.join(annotation_dir, file_name)  \n",
    "    with open(file_path, 'r') as f:  \n",
    "        data = json.load(f)  \n",
    "    print(f\"Model: {file_name}\")  \n",
    "    res, result_label_image = calculate(data)  \n",
    "    res_text, result_label_text = cal_text(data)  \n",
    "    merged_res = merge_results(file_name, res, res_text)  # 传递模型名称  \n",
    "    merged_results.append(merged_res)  \n",
    "    model_name = file_name.split(\"_\")[0]  \n",
    "    label_results_text[model_name] = result_label_text  \n",
    "    label_results_image[model_name] = result_label_image  \n",
    "  \n",
    "# 指定的模型顺序  \n",
    "model_order = [\"Meta-Llama-3.1-8B-Instruct\", \"Meta-Llama-3.1-70B-Instruct\", \"Qwen2-72B-Instruct\", \"tulu-2-dpo-70b\"]  \n",
    "  \n",
    "# 按指定顺序排序 merged_results  \n",
    "ordered_merged_results = sorted(merged_results, key=lambda x: model_order.index(x[\"model\"]) if x[\"model\"] in model_order else float('inf'))  \n",
    "  \n",
    "# 创建一个DataFrame并保存为CSV文件  \n",
    "df = pd.DataFrame(ordered_merged_results)  \n",
    "  \n",
    "# 确保模型名称是第一列  \n",
    "df = df[[\"model\", \"good_idx_image\", \"same_idx_image\", \"loss_idx_image\", \"sum_image\", \"good_idx_text\", \"same_idx_text\", \"loss_idx_text\", \"sum_text\"]]  \n",
    "  \n",
    "df.to_csv(\"merged_results.csv\", index=False)  \n",
    "print(\"Merged results saved to merged_results.csv\")  \n",
    "  \n",
    "# 保存 label_results_text 为 CSV 文件  \n",
    "label_text_df = pd.DataFrame.from_dict(label_results_text, orient='index').transpose()  \n",
    "label_text_df = label_text_df[model_order]  \n",
    "label_text_df.to_csv(\"label_results_text_70B.csv\", index=False)  \n",
    "print(\"Label results text saved to label_results_text.csv\")  \n",
    "  \n",
    "# 保存 label_results_image 为 CSV 文件  \n",
    "label_image_df = pd.DataFrame.from_dict(label_results_image, orient='index').transpose()  \n",
    "label_image_df = label_image_df[model_order]  \n",
    "label_image_df.to_csv(\"label_results_image_70B.csv\", index=False)  \n",
    "print(\"Label results image saved to label_results_image.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen2-72B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-8B-Instruct_sample.json\n",
      "Model: Meta-Llama-3.1-70B-Instruct_sample.json\n",
      "Model: tulu-2-dpo-70b_sample.json\n",
      "Merged results saved to merged_results.csv\n",
      "Label results text saved to label_results_text.csv\n",
      "Label results image saved to label_results_image.csv\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import os  \n",
    "import pandas as pd  \n",
    "  \n",
    "def calculate(data):  \n",
    "    good_idx = []  \n",
    "    same_idx = []  \n",
    "    loss_idx = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"score_1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"score_2\"]]  \n",
    "        if score_1 != score_2: \n",
    "            if score_1 == 3 and score_2 == 2:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\") \n",
    "            elif score_1 == 1 and score_2 == 2:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            elif score_1 == 2 and score_2 == 3:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\")\n",
    "            elif score_1 == 2 and score_2 == 1:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            else:\n",
    "                same_idx.append(idx)  \n",
    "                result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_1 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")   \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def cal_text(data):  \n",
    "    model_name = data[0][\"model_id_2\"]  \n",
    "    judge_data = read_jsonl(f\"data/arena-ta/model_judgment/gpt-4o_text/{model_name}.jsonl\")  \n",
    "    judge_dict = {item['question_id']: [item['games'][0]['score'], item['games'][0]['judgment'], item['games'][1]['score'], item['games'][1]['judgment']] for item in judge_data}  \n",
    "    res = []  \n",
    "    result_label = []  \n",
    "    for idx, item in enumerate(data):  \n",
    "        score_1 = judge_dict[item[\"question_id\"]][0]  \n",
    "        judge_1 = judge_dict[item[\"question_id\"]][1]  \n",
    "        score_2 = judge_dict[item[\"question_id\"]][2]  \n",
    "        judge_2 = judge_dict[item[\"question_id\"]][3]  \n",
    "        item[\"text_score1\"] = score_1  \n",
    "        item[\"text_judge1\"] = judge_1  \n",
    "        item[\"text_score2\"] = score_2  \n",
    "        item[\"text_judge2\"] = judge_2  \n",
    "        good_idx = []  \n",
    "        same_idx = []  \n",
    "        loss_idx = []  \n",
    "        res.append(item)  \n",
    "    for idx, item in enumerate(res[:50]):  \n",
    "        score_map_generall = {  \n",
    "            \"A>>B\": 3,  \n",
    "            \"A>B\": 3,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 1,  \n",
    "            \"B>>A\": 1,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_map_generall2 = {  \n",
    "            \"A>>B\": 1,  \n",
    "            \"A>B\": 1,  \n",
    "            \"A=B\": 2,  \n",
    "            \"B>A\": 3,  \n",
    "            \"B>>A\": 3,  \n",
    "            None: 0  \n",
    "        }  \n",
    "        score_1 = score_map_generall[item[\"text_score1\"]]  \n",
    "        score_2 = score_map_generall2[item[\"text_score2\"]]  \n",
    "        if score_1 != score_2: \n",
    "            if score_1 == 3 and score_2 == 2:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\") \n",
    "            elif score_1 == 1 and score_2 == 2:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            elif score_1 == 2 and score_2 == 3:\n",
    "                good_idx.append(idx)\n",
    "                result_label.append(\"W\")\n",
    "            elif score_1 == 2 and score_2 == 1:\n",
    "                loss_idx.append(idx)\n",
    "                result_label.append(\"L\")\n",
    "            else:\n",
    "                same_idx.append(idx)  \n",
    "                result_label.append(\"T\")  \n",
    "        elif score_1 == 3:  \n",
    "            good_idx.append(idx)  \n",
    "            result_label.append(\"W\")  \n",
    "        elif score_1 == 1:  \n",
    "            loss_idx.append(idx)  \n",
    "            result_label.append(\"L\")  \n",
    "        else:  \n",
    "            same_idx.append(idx)  \n",
    "            result_label.append(\"T\")  \n",
    "    result = {  \n",
    "        \"good_idx\": len(good_idx),  \n",
    "        \"same_idx\": len(same_idx),  \n",
    "        \"loss_idx\": len(loss_idx),  \n",
    "        \"sum\": len(good_idx) + len(same_idx) + len(loss_idx)  \n",
    "    }  \n",
    "    return result, result_label  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    with open(file_path, 'r') as file:  \n",
    "        return [json.loads(line) for line in file]  \n",
    "  \n",
    "def merge_results(model_name, image_res, text_res):  \n",
    "    merged_result = {  \n",
    "        \"model\": model_name,  # 添加模型名称到结果字典的第一项  \n",
    "        \"good_idx_image\": image_res[\"good_idx\"],  \n",
    "        \"same_idx_image\": image_res[\"same_idx\"],  \n",
    "        \"loss_idx_image\": image_res[\"loss_idx\"],  \n",
    "        \"sum_image\": image_res[\"sum\"],  \n",
    "        \"good_idx_text\": text_res[\"good_idx\"],  \n",
    "        \"same_idx_text\": text_res[\"same_idx\"],  \n",
    "        \"loss_idx_text\": text_res[\"loss_idx\"],  \n",
    "        \"sum_text\": text_res[\"sum\"]  \n",
    "    }  \n",
    "    return merged_result  \n",
    "  \n",
    "# 获取data/annotation/目录下的所有文件  \n",
    "annotation_dir = 'data/annotation_2/'  \n",
    "files = [f for f in os.listdir(annotation_dir) if os.path.isfile(os.path.join(annotation_dir, f))]  \n",
    "  \n",
    "merged_results = []  \n",
    "label_results_text = {}  \n",
    "label_results_image = {}  \n",
    "  \n",
    "# 遍历每个文件并进行calculate统计  \n",
    "for file_name in files:  \n",
    "    file_path = os.path.join(annotation_dir, file_name)  \n",
    "    with open(file_path, 'r') as f:  \n",
    "        data = json.load(f)  \n",
    "    print(f\"Model: {file_name}\")  \n",
    "    res, result_label_image = calculate(data)  \n",
    "    res_text, result_label_text = cal_text(data)  \n",
    "    merged_res = merge_results(file_name, res, res_text)  # 传递模型名称  \n",
    "    merged_results.append(merged_res)  \n",
    "    model_name = file_name.split(\"_\")[0]  \n",
    "    label_results_text[model_name] = result_label_text  \n",
    "    label_results_image[model_name] = result_label_image  \n",
    "  \n",
    "# 指定的模型顺序  \n",
    "model_order = [\"Meta-Llama-3.1-8B-Instruct\", \"Meta-Llama-3.1-70B-Instruct\", \"Qwen2-72B-Instruct\", \"tulu-2-dpo-70b\"]  \n",
    "  \n",
    "# 按指定顺序排序 merged_results  \n",
    "ordered_merged_results = sorted(merged_results, key=lambda x: model_order.index(x[\"model\"]) if x[\"model\"] in model_order else float('inf'))  \n",
    "  \n",
    "# 创建一个DataFrame并保存为CSV文件  \n",
    "df = pd.DataFrame(ordered_merged_results)  \n",
    "  \n",
    "# 确保模型名称是第一列  \n",
    "df = df[[\"model\", \"good_idx_image\", \"same_idx_image\", \"loss_idx_image\", \"sum_image\", \"good_idx_text\", \"same_idx_text\", \"loss_idx_text\", \"sum_text\"]]  \n",
    "  \n",
    "df.to_csv(\"merged_results2.csv\", index=False)  \n",
    "print(\"Merged results saved to merged_results.csv\")  \n",
    "  \n",
    "# 保存 label_results_text 为 CSV 文件  \n",
    "label_text_df = pd.DataFrame.from_dict(label_results_text, orient='index').transpose()  \n",
    "label_text_df = label_text_df[model_order]  \n",
    "label_text_df.to_csv(\"label_results_text_70B2.csv\", index=False)  \n",
    "print(\"Label results text saved to label_results_text.csv\")  \n",
    "  \n",
    "# 保存 label_results_image 为 CSV 文件  \n",
    "label_image_df = pd.DataFrame.from_dict(label_results_image, orient='index').transpose()  \n",
    "label_image_df = label_image_df[model_order]  \n",
    "label_image_df.to_csv(\"label_results_image_70B2.csv\", index=False)  \n",
    "print(\"Label results image saved to label_results_image.csv\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
